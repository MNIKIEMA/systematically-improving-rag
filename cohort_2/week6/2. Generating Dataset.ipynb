{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Systematically Improving Your Rag Application\n",
    "\n",
    "> If you haven't ran the previous notebook `1. Evaluate Tools.ipynb`, please do so before continuing. A lot of the code in this notebook will be based off the evaluation methods that we cover in that notebook.\n",
    "\n",
    "In this notebook, we'll look at how we can boost our RAG model's ability to select and execute the correct tooling based off user commands. \n",
    "\n",
    "We'll do so in 3 steps\n",
    "\n",
    "1. **Generating Synthetic Queries**: We'll first start by generating some initial queries to benchmark our model's tool calling ability and identify failure points that our model might struggle with\n",
    "2. **Benchmarking Model Performance**: Next, we'll use our initial queries to establish a baseline of our model's tool calling ability\n",
    "3. **Improving Model Performance**: Finally, we'll look at how we can improve the performance of our model through the use of few shot examples and system prompts that a user can provide to the model to describe his/her usage patterns.\n",
    "\n",
    "By starting off with a synthetic dataset, we can gain insight into specific areas where our model might struggle and use that to iteratively improve our model's tool calling ability. With enough user data, we'll also be able to blend in user queries into our dataset to make it more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import BaseModel, computed_field\n",
    "\n",
    "\n",
    "class Command(BaseModel):\n",
    "    extension_name: str\n",
    "    command_name: str\n",
    "    command_description: str\n",
    "\n",
    "    @computed_field\n",
    "    def key(self) -> str:\n",
    "        return f\"{self.extension_name}.{self.command_name}\"\n",
    "\n",
    "\n",
    "def load_commands(commands_path: str):\n",
    "    with open(commands_path, \"r\") as f:\n",
    "        return [\n",
    "            Command(\n",
    "                extension_name=command[\"extension_name\"],\n",
    "                command_name=command[\"source_name\"],\n",
    "                command_description=command[\"description\"],\n",
    "            )\n",
    "            for command in json.load(f)\n",
    "        ]\n",
    "\n",
    "\n",
    "commands = load_commands(\"raw_commands.json\")\n",
    "print(len(commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a dataset that tests single command calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Create an issue: Problem integrating Next Auth into the new frontend deployment; authentication failures. Assign to John Smith.',\n",
       " 'labels': ['jira.create-issue']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "import google.generativeai as genai\n",
    "from pydantic import field_validator, ValidationInfo\n",
    "import random\n",
    "import re\n",
    "\n",
    "client = instructor.from_gemini(\n",
    "    genai.GenerativeModel(\"gemini-1.5-flash-latest\"), use_async=True\n",
    ")\n",
    "\n",
    "\n",
    "class UserQuery(BaseModel):\n",
    "    query: str\n",
    "\n",
    "    @field_validator(\"query\")\n",
    "    def validate_query(cls, v, info: ValidationInfo):\n",
    "        application = info.context[\"command\"].extension_name\n",
    "        if application.lower() in v.lower():\n",
    "            raise ValueError(\n",
    "                f\"Do not mention the application name {application} in the query. Rewrite the query of {v} so that it does not mention the application name or add specific details that allude to it instead. This includes web links that might be in the query.\"\n",
    "            )\n",
    "\n",
    "        return re.sub(r\"\\\\{1,}\", \"\", v.replace('\"', \"'\").strip())\n",
    "\n",
    "\n",
    "async def generate_question(client, command: Command, commands: list[Command]):\n",
    "    length = random.randint(\n",
    "        10, 50\n",
    "    )  # Increased max length to allow for more conversational queries\n",
    "    tone = random.choice(\n",
    "        [\n",
    "            \"formal_request (Eg. Could you please assist me in...)\",  # \"Could you please assist me in...\"\n",
    "            \"imperative command (Eg. add a new event to the calendar for tomorrow at 10am with Jeffrey)\",  # \"hey can u help me with...\"\n",
    "            \"voice_transcript (Eg. yeah um so I need to like...)\",  # \"yeah um so I need to like...\"\n",
    "        ]\n",
    "    )\n",
    "    modification = random.choice(\n",
    "        [\n",
    "            \"perfect_english\",\n",
    "            \"typos_and_misspellings\",  # \"recieved\", \"tommorow\", etc\n",
    "            \"missing_punctuation\",  # no periods or commas\n",
    "            \"abbreviated_words\",  # \"pls\", \"thx\", \"u\", \"tmrw\"\n",
    "            \"voice_to_text_errors\",  # misheard words, run-on sentences\n",
    "            \"random_capitalization\",  # \"Can You Help ME with\"\n",
    "            \"extra_spaces_or_no_spaces\",  # \"help  me    with\" or \"helpme with\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                Generate a user message that requires the following tool to be called. This should be in the imperative (Eg. \"Create a new issue for the problems we're facing integrating next auth in the new deployment of the frontend\") instead of a question (Can you help me to...)\n",
    "\n",
    "                <command>\n",
    "                Name: {{ command.key }}\n",
    "                Description: {{ command.command_description }}\n",
    "                </command>\n",
    "\n",
    "                Here are all of the commands that the user has available to them. Make sure that you user query is formulated specifically to call the right command.\n",
    "\n",
    "                <other_commands>\n",
    "                {% for command in commands %}\n",
    "                    <command>\n",
    "                    Name: {{ command.key }}\n",
    "                    Description: {{ command.command_description }}\n",
    "                    </command>\n",
    "                {% endfor %}\n",
    "                </other_commands>\n",
    "\n",
    "                Do not mention the extension name of {{ command.extension_name }} or the command name in the query where posible of adding specific details that allude to it instead.\n",
    "\n",
    "                - The query should be {{ length }} words long with a {{tone}} tone. Note that the query should be written with {{ modification }}\n",
    "                - Be specific with the query and give specific details. For instance, send a slack message is a bad example since don't have any of the information about the channel to call. A better example here is #general update that we're moving ahead with the second prototype for the new frontend auth feature.\n",
    "                - Be creative - Eg. when generating a user query for get-unread-notifications, don't just say hey get me my open pull requests. Notifications are more broad than just pull requests - they include things like comments, mentions , security alerts and deployment status etc. So we might say \"Can you help me check if I have any PRs to review and whether there are any security alerts for the repo?\"\n",
    "\n",
    "                Here are some bad examples. Refer to them when generating the query but do not copy the specific packages or examples that we're using here, make sure to invent something new.\n",
    "                <bad examples>\n",
    "                Eg. Query: Report a new issue: the new frontend auth prototype is moving to the second version\n",
    "                    label: jira.create-issue\n",
    "                \n",
    "                Evaluation: This is not a great example because the query is so general. A better query here instead might be \"create new issue for the problems we're facing integrating next auth in the new deployment of the frontend\" because we give specific packages that are involved and the exact project it's from.\n",
    "                </examples>\n",
    "\n",
    "                Here's some context for how each individual extension is used. Make sure to refer closely and use the context to formulate the query.\n",
    "                <context>\n",
    "                - Slack is used for joining specific channels to get support for help. Eg. Send to Modal-support : having issues with deployment. Send to comfy-ui : having issues with the UI.\n",
    "                - Microsoft Teams is used for work related communication - Eg. Schedule a quarterly review with Sarah, ping my team that I'll be 5 minutes late to standup\n",
    "                - Discord is used for personal gaming and online communities -> Eg. ask the squad if anyone's up for some raids tonight? Tell Thomas i'll be on in 10 for Helldivers\n",
    "                - Github is used for code related communication - Eg. Show me my PRs, create a pull request for the new feature and for code discussions about specific implementation\n",
    "                - Jira is used to track the specific task/issue/bugs. Eg. Find all issues with the summary containing 'Bug Fix' and status 'Open' plz\n",
    "                - Confluence is used for work related documenation - Eg. what's the onboarding process for new employees?\n",
    "                - Apple Notes is used for personal note taking - Eg. Help create a note about the shopping list for the christmas dinner - need 3 eggs, some ham, and some cheese\n",
    "                - Obsidian is used for personal knowledge base - Eg. Help me find the notes on the latest research paper on large language models\n",
    "                - Notion is used for planning things like trips ( create pages as the default but let's use tables to track things like spending/other expenses that benefit from a table format)\n",
    "                </context>\n",
    "                \"\"\",\n",
    "            }\n",
    "        ],\n",
    "        context={\n",
    "            \"command\": command,\n",
    "            \"commands\": commands,\n",
    "            \"length\": length,\n",
    "            \"tone\": tone,\n",
    "            \"modification\": modification,\n",
    "        },\n",
    "        response_model=UserQuery,\n",
    "    )\n",
    "    return {\"query\": response.query, \"labels\": [command.key]}\n",
    "\n",
    "\n",
    "await generate_question(client, commands[0], commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736257627.811979  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "\n",
    "questions = await asyncio.gather(\n",
    "    *[\n",
    "        generate_question(client, command, commands)\n",
    "        for command in random.sample(commands, 10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries.jsonl\", \"w\") as f:\n",
    "    for question in questions:\n",
    "        f.write(json.dumps(question) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure the performance of our model on these initial queries. We'll do so by loading in the queries and then using the `generate_commands` function to generate the commands that the model should call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def load_queries(commands: list[Command], query_path: str):\n",
    "    valid_commands = set(command.key for command in commands)\n",
    "    with open(query_path, \"r\") as f:\n",
    "        queries = [json.loads(line) for line in f]\n",
    "        for query in queries:\n",
    "            for label in query[\"labels\"]:\n",
    "                if label not in valid_commands:\n",
    "                    raise ValueError(f\"Command {label} not found in commands\")\n",
    "    return queries\n",
    "\n",
    "\n",
    "commands = load_commands(\"raw_commands.json\")\n",
    "queries = load_queries(commands, \"queries.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commands(BaseModel):\n",
    "    chain_of_thought: str\n",
    "    commands: list[str]\n",
    "\n",
    "    @field_validator(\"commands\")\n",
    "    def validate_commands(cls, v: list[str], info: ValidationInfo):\n",
    "        context = info.context\n",
    "        commands = context[\"commands\"]\n",
    "        command_names = set([command.key for command in commands])\n",
    "        for command in v:\n",
    "            if command not in command_names:\n",
    "                raise ValueError(f\"Command {command} not found in commands\")\n",
    "\n",
    "        assert len(v) >= 1, \"At least one command must be called\"\n",
    "\n",
    "        return v\n",
    "\n",
    "\n",
    "async def generate_commands(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[Command]\n",
    "):\n",
    "    resp = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant. You must call a tool in response to the user query below.\n",
    "                \n",
    "                Refer to the command description to identify the right command to call and make sure to return the command name in your final response.\n",
    "\n",
    "                Here is some information on the system\n",
    "\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                    <command>\n",
    "                    Name: {{ command.key }}\n",
    "                    Description: {{ command.description}}\n",
    "                    </command>\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736260567.542956  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736260567.555241  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736260567.566884  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736260567.576443  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736260567.588280  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736260567.597531  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736260567.606499  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Experiment week-6-1736260569 is running at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1736260569\n",
      "function-calling (data): 14it [00:00, 52475.65it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2d33609d234313ad1c34a1016ed1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "function-calling (tasks):   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-6-1736260569 compared to week-6-1736260526:\n",
      "65.50% (+07.14%) 'recall'    score\t(2 improvements, 1 regressions)\n",
      "65.64% (-03.43%) 'precision' score\t(2 improvements, 1 regressions)\n",
      "\n",
      "1736260569.22s start\n",
      "1736260570.65s end\n",
      "1.42s (+29.75%) 'duration'\t(7 improvements, 7 regressions)\n",
      "\n",
      "See results for week-6-1736260569 at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1736260569\n"
     ]
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import calculate_precision, calculate_recall\n",
    "import openai\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    return [\n",
    "        Score(\n",
    "            name=\"precision\",\n",
    "            score=calculate_precision(output, kwargs[\"expected\"]),\n",
    "        ),\n",
    "        Score(\n",
    "            name=\"recall\",\n",
    "            score=calculate_recall(output, kwargs[\"expected\"]),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "client = instructor.from_gemini(\n",
    "    genai.GenerativeModel(\"gemini-1.5-flash-latest\"), use_async=True\n",
    ")\n",
    "commands = load_commands(\"raw_commands.json\")\n",
    "queries = load_queries(commands, \"queries.jsonl\")\n",
    "\n",
    "async def task(query: str, hooks):\n",
    "    return await generate_commands(query, client, commands)\n",
    "\n",
    "\n",
    "base_case = await Eval(\n",
    "    \"function-calling\",\n",
    "    data=lambda: [\n",
    "        {\n",
    "            \"input\": row[\"query\"],\n",
    "            \"expected\": row[\"labels\"],\n",
    "        }\n",
    "        for row in queries\n",
    "    ],\n",
    "    task=task,\n",
    "    max_concurrency=10,\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a good baseline, let's generate more queries and see if we can improve our model's performance. We'll do so by reading from `queries.jsonl`, finding examples for the specific command we're interested in and then choosing another 3-4 other examples that are from other commands.\n",
    "\n",
    "This will help us to be able to introduce some degree of diversity in our dataset and generate more tricky queries that test the model's ability to call the right command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "commands = load_commands(\"raw_commands.json\")\n",
    "queries = load_queries(commands, \"queries.jsonl\")\n",
    "\n",
    "command_to_query = defaultdict(list)\n",
    "for query in queries:\n",
    "    for label in query[\"labels\"]:\n",
    "        command_to_query[label].append(query[\"query\"])\n",
    "all_queries = [query[\"query\"] for query in queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these new queries, we can then generate more complex queries that test the model's ability to call the right command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"search github issues tagged 'backend' and create a ticket for the ones causing prod errors\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'jira.create-issue'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'github.search-issues'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'query'\u001b[0m: \u001b[32m\"search github issues tagged 'backend' and create a ticket for the ones causing prod errors\"\u001b[0m,\n",
       "    \u001b[32m'labels'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'jira.create-issue'\u001b[0m, \u001b[32m'github.search-issues'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import instructor\n",
    "import google.generativeai as genai\n",
    "import random\n",
    "from rich import print\n",
    "\n",
    "client = instructor.from_gemini(\n",
    "    genai.GenerativeModel(\"gemini-2.0-flash-exp\"), use_async=True\n",
    ")\n",
    "\n",
    "class MultiCommandQuery(BaseModel):\n",
    "    query: str\n",
    "    commands: list[str]\n",
    "\n",
    "    @field_validator(\"commands\")\n",
    "    def validate_commands(cls, v: list[str], info: ValidationInfo):\n",
    "        context = info.context\n",
    "        commands = context[\"commands\"]\n",
    "        command_names = set([command.key for command in commands])\n",
    "        for command in v:\n",
    "            if command not in command_names:\n",
    "                raise ValueError(f\"Command {command} not found in commands\")\n",
    "        return v\n",
    "\n",
    "async def generate_question_with_examples(\n",
    "    client,\n",
    "    command: Command,\n",
    "    commands: list[Command],\n",
    "    query_to_examples: dict,\n",
    "    queries: list[str],\n",
    "):\n",
    "    length = random.randint(\n",
    "        10, 20\n",
    "    )  # Increased max length to allow for more conversational queries\n",
    "    tone = random.choice(\n",
    "        [\n",
    "            \"formal_request\",  # \"Could you please assist me in...\"\n",
    "            \"imperative command\",  # \"hey can u help me with...\"\n",
    "            \"voice_transcript\",  # \"yeah um so I need to like...\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    command_examples = query_to_examples[command.key]\n",
    "    selected_examples = random.sample(command_examples, min(3, len(command_examples)))\n",
    "\n",
    "    other_examples = random.sample(\n",
    "        [query for query in queries if query not in selected_examples], 3\n",
    "    )\n",
    "    selected_counter_examples = random.sample(other_examples, 3)\n",
    "\n",
    "    response = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                Generate a hypothetical user query that requires the following command to be called in conjunction with at most 2 other commands that you are given below. This should make logical sense\n",
    "\n",
    "                eg. user has a bug that they need to log in confluence + jira\n",
    "                Eg. user wants to pull out his shopping list for the wine he likes and then see if it's on amazon\n",
    "                Eg. user wants to search for the latest research paper on large language models and then create a new note in their obsidian vault\n",
    "\n",
    "                Users for instance would not\n",
    "                - track issues in github and jira at the same time. Instead they might start a discussion in github but then create a jira issue to track it\n",
    "                \n",
    "                This is the command you must include\n",
    "                <command>\n",
    "                Name: {{ command.key }}\n",
    "                Description: {{ command.command_description }}\n",
    "                </command>\n",
    "\n",
    "                Here are the other commands that the user has available to them which you can combine with the command above to be called.\n",
    "\n",
    "                <other_commands>\n",
    "                {% for command in commands %}\n",
    "                    <command>\n",
    "                    Name: {{ command.key }}\n",
    "                    Description: {{ command.command_description }}\n",
    "                    </command>\n",
    "                {% endfor %}\n",
    "                </other_commands>\n",
    "\n",
    "                Here are some examples of how the user might ask for this command. Refer closely to these examples for how to formulate the user command but do not copy any of the details in these examples. Come up with new examples that are similar but not exactly the same.\n",
    "                <examples>\n",
    "                {% for query in selected_examples %}\n",
    "                    - {{ query }}\n",
    "                {% endfor %}\n",
    "                </examples>\n",
    "\n",
    "                Here are some contrastive examples of how the user will not ask for this command. Look closely at these examples and make sure that your query is not similar to any of these.\n",
    "\n",
    "                <counter_examples>\n",
    "                {% for query in selected_counter_examples %}\n",
    "                    - {{ query }}\n",
    "                {% endfor %}\n",
    "                </counter_examples>\n",
    "\n",
    "                Do not mention the extension name of {{ command.extension_name }} or the command name in the query where posible of adding specific details that allude to it instead.\n",
    "\n",
    "                - The query should be {{ length }} words long with a {{tone}} tone. The query should be written casually and naturally.\n",
    "                - Be specific with the query and give specific details. For instance, send a slack message is a bad example since don't have any of the information about the channel to call. A better example here is #general update that we're moving ahead with the second prototype for the new frontend auth feature.\n",
    "                - Be creative - Eg. when generating a user query for get-unread-notifications, don't just say hey get me my open pull requests. Notifications are more broad than just pull requests - they include things like comments, mentions , security alerts and deployment status etc. So we might say \"Can you help me check if I have any PRs to review and whether there are any security alerts for the repo?\"\n",
    "\n",
    "                Here's some context for how each individual extension is used. Make sure to refer closely and use the context to formulate the query.\n",
    "                <context>\n",
    "                - Slack is used for joining specific channels to get support for help. Eg. Send to Modal-support : having issues with deployment. Send to comfy-ui : having issues with the UI.\n",
    "                - Microsoft Teams is used for work related communication - Eg. Schedule a quarterly review with Sarah, ping my team that I'll be 5 minutes late to standup\n",
    "                - Discord is used for personal gaming and online communities -> Eg. ask the squad if anyone's up for some raids tonight? Tell Thomas i'll be on in 10 for Helldivers\n",
    "                - Github is used for code related communication - Eg. Show me my PRs, create a pull request for the new feature and for code discussions about specific implementation\n",
    "                - Jira is used to track the specific task/issue/bugs. Eg. Find all issues with the summary containing 'Bug Fix' and status 'Open' plz\n",
    "                - Confluence is used for work related documenation - Eg. what's the onboarding process for new employees?\n",
    "                - Apple Notes is used for personal note taking - Eg. Help create a note about the shopping list for the christmas dinner - need 3 eggs, some ham, and some cheese\n",
    "                - Obsidian is used for personal knowledge base - Eg. Help me find the notes on the latest research paper on large language models\n",
    "                - Notion is used for planning things like trips ( create pages as the default but let's use tables to track things like spending/other expenses that benefit from a table format)\n",
    "                </context>\n",
    "                \"\"\",\n",
    "            }\n",
    "        ],\n",
    "        context={\n",
    "            \"command\": command,\n",
    "            \"commands\": commands,\n",
    "            \"length\": length,\n",
    "            \"tone\": tone,\n",
    "            \"selected_examples\": selected_examples,\n",
    "            \"selected_counter_examples\": selected_counter_examples,\n",
    "        },\n",
    "        response_model=MultiCommandQuery,\n",
    "    )\n",
    "    return {\"query\": response.query, \"labels\": response.commands}\n",
    "\n",
    "\n",
    "print(await generate_question_with_examples(client, commands[0], commands, command_to_query, all_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "\n",
    "questions = await asyncio.gather(\n",
    "    *[\n",
    "        generate_question_with_examples(client, command, commands, command_to_query, all_queries)\n",
    "        for command in random.sample(commands, 5)\n",
    "    ]\n",
    ")\n",
    "with open(\"queries.jsonl\", \"a\") as f:\n",
    "    for question in questions:\n",
    "        f.write(json.dumps(question) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_commands_with_system_prompt(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[Command]\n",
    "):\n",
    "    resp = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant. You must call a tool in response to the user query below.\n",
    "                \n",
    "                Refer to the command description to identify the right command to call and make sure to return the command name in your final response.\n",
    "\n",
    "                Here is some information on the system\n",
    "\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                    <command>\n",
    "                    Name: {{ command.key }}\n",
    "                    Description: {{ command.description}}\n",
    "                    </command>\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "\n",
    "                Here are some instructions on how to choose the right extension and command in response to the user query below.\n",
    "                <instructions>\n",
    "                Code Review\n",
    "                - Jira is for tracking issues \n",
    "                - Github is for everything else, so direct discussions, pull requests etc there. But all github issues are going to be tracked in jira\n",
    "\n",
    "                Note taking apps:\n",
    "                - Apple Notes: Shopping lists and quick notes\n",
    "                - Obsidian: Personal knowledge base (MOOCs, learning resources)\n",
    "                - Confluence: All work documentation and wikis ( so in case there's an incident report, it goes here)\n",
    "                - Notion: Trip planning (use pages by default, tables for tracking expenses)\n",
    "\n",
    "                When available, use AI features to auto-generate content for new pages/documents\n",
    "                </instructions>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_commands_with_system_prompt(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[Command]\n",
    "):\n",
    "    resp = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant. You must call a tool in response to the user query below.\n",
    "                \n",
    "                Refer to the command description to identify the right command to call and make sure to return the command name in your final response.\n",
    "\n",
    "                Here is some information on the system\n",
    "\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                    <command>\n",
    "                    Name: {{ command.key }}\n",
    "                    Description: {{ command.description}}\n",
    "                    </command>\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "\n",
    "                Here are some instructions on how to choose the right extension and command in response to the user query below.\n",
    "                <instructions>\n",
    "                Code Review\n",
    "                - Jira is for tracking issues \n",
    "                - Github is for everything else, so direct discussions, pull requests etc there. But all github issues are going to be tracked in jira\n",
    "\n",
    "                Note taking apps:\n",
    "                - Apple Notes: Shopping lists and quick notes\n",
    "                - Obsidian: Personal knowledge base (MOOCs, learning resources)\n",
    "                - Confluence: All work documentation and wikis ( so in case there's an incident report, it goes here)\n",
    "                - Notion: Trip planning (use pages by default, tables for tracking expenses)\n",
    "\n",
    "                When available, use AI features to auto-generate content for new pages/documents\n",
    "                </instructions>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n",
    "\n",
    "async def generate_commands_with_system_prompt_and_examples(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[Command]\n",
    "):\n",
    "    resp = await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant. You must call a tool in response to the user query below.\n",
    "                \n",
    "                Refer to the command description to identify the right command to call and make sure to return the command name in your final response.\n",
    "\n",
    "                Here is some information on the system\n",
    "\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                    <command>\n",
    "                    Name: {{ command.key }}\n",
    "                    Description: {{ command.description}}\n",
    "                    </command>\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "\n",
    "                Here are some instructions on how to choose the right extension and command in response to the user query below.\n",
    "                <instructions>\n",
    "                Code Review\n",
    "                - Jira is for tracking issues \n",
    "                - Github is for everything else, so direct discussions, pull requests etc there. But all github issues are going to be tracked in jira\n",
    "\n",
    "                Note taking apps:\n",
    "                - Apple Notes: Shopping lists and quick notes\n",
    "                - Obsidian: Personal knowledge base (MOOCs, learning resources)\n",
    "                - Confluence: All work documentation and wikis ( so in case there's an incident report, it goes here)\n",
    "                - Notion: Trip planning (use pages by default, tables for tracking expenses)\n",
    "\n",
    "                When available, use AI features to auto-generate content for new pages/documents\n",
    "                </instructions>\n",
    "\n",
    "                Here are some examples of how the user might ask for different commands\n",
    "\n",
    "                <examples>\n",
    "                - Query: Find my PR tagged with the issue number A2231\n",
    "                  Expected: github.search-issues\n",
    "                \n",
    "                - Query : grab pinned shopping list in apple notes and search amazon for the items\n",
    "                  Expected: apple-notes.menu-bar, amazon-search.index\n",
    "                \n",
    "                - Query : Can you check if the workflow for the PR I just created failed?\n",
    "                  Expected: github.my-pull-requests, github.workflow-runs\n",
    "                </examples>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736262009.331828  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262009.345252  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262009.358910  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262009.369393  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262009.382507  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262009.392530  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262009.401599  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Experiment week-6-1736262011 is running at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1736262011\n",
      "function-calling (data): 18it [00:00, 18789.81it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e296562b59554f7f8a1a0646c880e4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "function-calling (tasks):   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-6-1736262011 compared to week-6-1736261331:\n",
      "55.56% (-08.33%) 'recall'    score\t(1 improvements, 3 regressions)\n",
      "66.78% (-11.00%) 'precision' score\t(2 improvements, 3 regressions)\n",
      "\n",
      "1736262012.07s start\n",
      "1736262013.98s end\n",
      "1.91s (+87.47%) 'duration'\t(2 improvements, 16 regressions)\n",
      "\n",
      "See results for week-6-1736262011 at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1736262011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736262018.920904  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262018.968558  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262018.981860  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262018.992721  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262019.005649  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262019.015496  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1736262019.025426  903017 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "Experiment week-6-1736262020 is running at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1736262020\n",
      "function-calling (data): 18it [00:00, 175984.78it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5d34824f154189b3fe9746d7a4b126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "function-calling (tasks):   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-6-1736262020 compared to week-6-1736262011:\n",
      "66.67% (+11.11%) 'recall'    score\t(4 improvements, 1 regressions)\n",
      "80.56% (+13.78%) 'precision' score\t(4 improvements, 2 regressions)\n",
      "\n",
      "1736262020.70s start\n",
      "1736262022.02s end\n",
      "1.31s (-59.57%) 'duration'\t(14 improvements, 4 regressions)\n",
      "\n",
      "See results for week-6-1736262020 at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1736262020\n"
     ]
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import calculate_precision, calculate_recall\n",
    "import openai\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    return [\n",
    "        Score(\n",
    "            name=\"precision\",\n",
    "            score=calculate_precision(output, kwargs[\"expected\"]),\n",
    "        ),\n",
    "        Score(\n",
    "            name=\"recall\",\n",
    "            score=calculate_recall(output, kwargs[\"expected\"]),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "client = instructor.from_gemini(\n",
    "    genai.GenerativeModel(\"gemini-1.5-flash-latest\"), use_async=True\n",
    ")\n",
    "commands = load_commands(\"raw_commands.json\")\n",
    "queries = load_queries(commands, \"queries.jsonl\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for select_command, label in [\n",
    "    (generate_commands, \"base\"),\n",
    "    (generate_commands_with_system_prompt, \"system prompt\"),\n",
    "    (generate_commands_with_system_prompt_and_examples, \"system prompt and examples\"),\n",
    "]:\n",
    "\n",
    "    async def task(query: str, hooks):\n",
    "        return await select_command(query, client, commands)\n",
    "\n",
    "    result = await Eval(\n",
    "        \"function-calling\",\n",
    "        data=lambda: [\n",
    "            {\n",
    "                \"input\": row[\"query\"],\n",
    "                \"expected\": row[\"labels\"],\n",
    "            }\n",
    "            for row in queries\n",
    "        ],\n",
    "        task=task,\n",
    "        max_concurrency=10,\n",
    "        scores=[evaluate_braintrust],\n",
    "    )\n",
    "    scores = {k: result.summary.scores[k].score for k in result.summary.scores}\n",
    "    results.append(\n",
    "        {\n",
    "            \"label\": label,\n",
    "            **scores,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system prompt</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  recall  precision\n",
       "0           base    0.69       0.62\n",
       "1  system prompt    0.72       0.66"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(results).round(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

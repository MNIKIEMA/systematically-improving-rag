{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Systematically Improving Your Rag Application\n",
    "\n",
    "> If you haven't ran the previous notebook `1. Evaluate Tools.ipynb`, please do so before continuing. A lot of the code in this notebook will be based off the evaluation methods that we cover in that notebook.\n",
    "\n",
    "# Generating Our Dataset\n",
    "\n",
    "We've defined a list of commands that we want to evaluate in our dataset in the `commands.yaml` file. In this specific notebook, we'll be generating a synthetic dataset of user requests that we can use to evaluate our mode's ability to call the commands that we've defined.\n",
    "\n",
    "Before we start generating our dataset, let's first understand what our model might struggle with. When it comes to deciding what tools to call, there are a few common failure points that a personal assistant might face.\n",
    "\n",
    "1. **A Lack Of Context** : It's common for users to use multiple note taking apps. We have Notion for company documents, Obsidian for personal notes and Apple Notes for quick notes that are more ephemeral. But it's difficult for a language model to know exactly which app to use when the user makes a request like `Sarah just got back to me on the project that our campaign was approved. can you make a note in our project page about it?` vs `I'm going shopping for groceries later, can you remind me that i need to buy milk, eggs and bread?`\n",
    "\n",
    "We might guess that the user might want notion but we can't assume that.\n",
    "\n",
    "2. **Multi-Step Tasks** : When we start scaling out our application to support calling multiple applications, we might find that our model struggles with multi-step tasks. For instance, given the request `create a new feature branch for the UI refactor and link all the tickets you've found about onboarding issues in the PR description`, we might find that our model struggles to call the required tools in the correct order or even call the tools at all.\n",
    "\n",
    "Being able to simulate these failure points in our synthetic dataset will help us to understand how our model performs in these scenarios. In this notebook, we'll do so in a few steps\n",
    "\n",
    "1. **Identifying Failure Points** : We'll first start by looking at how our model performs with simple/multi-step tasks to see how these failure points manifest themselves and start thinking about how we can generate synthetic queries that challenge our model which mimic these failure points\n",
    "\n",
    "2. **Generating Synthetic Questions** : We'll start by generating some initial queries. Once we're satisfied with the quality of the queries, we'll then generate more queries by sampling from these generated queries. We'll then use these queries to benchmark the precision and recall of our model's function calls and establish an initial baseline\n",
    "\n",
    "3. **Improving Performance** : Once we've established a simple baseline, we'll explore a few different strategies to improve the performance of our model. These include better descriptions of our commands, better prompts and some hard-coded few shot examples.\n",
    "\n",
    "Throughout this process, we'll be using `braintrust` to log all of our experiments so that it's easy for us to see the results of our experiments and share them with the rest of the team. \n",
    "\n",
    "Once we've done so in this notebook, we'll then proceed to evaluate other strategies such as dynamic retrieval of tools and few shot examples in a subsequent notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Failure Points\n",
    "\n",
    "Let's start by loading in our commands from the `commands.yaml` file. This contains a list of extensions and commands that we've manually cleaned and extracted from the Raycast Documentation.\n",
    "\n",
    "We've also added a small `description` field here that explains what our hypothetical users uses the extension for. This will help us to generate more challenging queries that require the model to understand the context of the user's request.\n",
    "\n",
    "When we generate synthetic queries, we want to randomly sample the commands to generate a diverse set of queries. Therefore, we want to flatten the dictionary of commands into a single flattened list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I use obsidian to take down notes when I'm studying or taking online courses. I've been taking </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a variety of different courses on topics such as machine learning, marketing, copywriting etc. I'll use this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific extension when I want to search for notes on a specific topic or ask questions about a topic. Sometimes I </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">might also want to create a quick dailyNote to log my progress for the day.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'commands'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'searchNote'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Full-text search across all vault notes and their metadata'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dailyNote'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Create or open the daily note file in your configured daily notes folder'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'createNote'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Create a new markdown note in your specified vault location'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'description'\u001b[0m: \u001b[32m\"I use obsidian to take down notes when I'm studying or taking online courses. I've been taking \u001b[0m\n",
       "\u001b[32ma variety of different courses on topics such as machine learning, marketing, copywriting etc. I'll use this \u001b[0m\n",
       "\u001b[32mspecific extension when I want to search for notes on a specific topic or ask questions about a topic. Sometimes I \u001b[0m\n",
       "\u001b[32mmight also want to create a quick dailyNote to log my progress for the day.\"\u001b[0m,\n",
       "    \u001b[32m'commands'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'searchNote'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m'Full-text search across all vault notes and their metadata'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'dailyNote'\u001b[0m,\n",
       "            \u001b[32m'description'\u001b[0m: \u001b[32m'Create or open the daily note file in your configured daily notes folder'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'createNote'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m'Create a new markdown note in your specified vault location'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "from rich import print\n",
    "\n",
    "with open(\"commands.yaml\", \"r\") as f:\n",
    "    commands = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "print(commands[\"extensions\"][\"obsidian\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'command_name': 'searchNote',\n",
       " 'extension_name': 'obsidian',\n",
       " 'extension_description': \"I use obsidian to take down notes when I'm studying or taking online courses. I've been taking a variety of different courses on topics such as machine learning, marketing, copywriting etc. I'll use this specific extension when I want to search for notes on a specific topic or ask questions about a topic. Sometimes I might also want to create a quick dailyNote to log my progress for the day.\",\n",
       " 'command_description': 'Full-text search across all vault notes and their metadata'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def read_and_flatten_commands(file_path: str):\n",
    "    # Load and parse the commands.yaml file\n",
    "    with open(file_path, \"r\") as file:\n",
    "        commands_data = yaml.safe_load(file)\n",
    "\n",
    "    # Extract extensions\n",
    "    extensions = commands_data[\"extensions\"]\n",
    "    commands = []\n",
    "\n",
    "    for extension_name, extension_data in extensions.items():\n",
    "        for command in extension_data[\"commands\"]:\n",
    "            commands.append(\n",
    "                {\n",
    "                    \"command_name\": command[\"name\"],\n",
    "                    \"extension_name\": extension_name,\n",
    "                    \"extension_description\": extension_data[\"description\"],\n",
    "                    \"command_description\": command[\"description\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return commands\n",
    "\n",
    "\n",
    "commands = read_and_flatten_commands(\"commands.yaml\")\n",
    "commands[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded in the commands, let's start by seeing how our model gets confused by the commands. Let's imagine we have three commands that we want to evalute\n",
    "\n",
    "- `obsidian.search`\n",
    "- `apple-notes.search`\n",
    "- `notion.search`\n",
    "\n",
    "Without much context or description of what the extension's command does, we might expect our model to get confused. This is ok because it provides a simple baseline to begin with. Let's see this in action below where our model gets the tool call wrong for every single query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Seems like the missing ingredient for the hamburger recipe was msg, let's add that in to our Beef Cheeseburger \n",
       "recipe note - Expected: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'apple-notes.search'</span><span style=\"font-weight: bold\">]</span> - Actual: obsidian.search\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Seems like the missing ingredient for the hamburger recipe was msg, let's add that in to our Beef Cheeseburger \n",
       "recipe note - Expected: \u001b[1m[\u001b[0m\u001b[32m'apple-notes.search'\u001b[0m\u001b[1m]\u001b[0m - Actual: obsidian.search\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What did I write about LSTMs previously? - Expected: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'obsidian.search'</span><span style=\"font-weight: bold\">]</span> - Actual: obsidian.search\n",
       "</pre>\n"
      ],
      "text/plain": [
       "What did I write about LSTMs previously? - Expected: \u001b[1m[\u001b[0m\u001b[32m'obsidian.search'\u001b[0m\u001b[1m]\u001b[0m - Actual: obsidian.search\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Can you note down that Jeanine is the new person in charge of the onboarding team in our team docs? - Expected: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'notion.search'</span><span style=\"font-weight: bold\">]</span> - Actual: obsidian.search\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Can you note down that Jeanine is the new person in charge of the onboarding team in our team docs? - Expected: \n",
       "\u001b[1m[\u001b[0m\u001b[32m'notion.search'\u001b[0m\u001b[1m]\u001b[0m - Actual: obsidian.search\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from typing import Literal\n",
    "from rich import print\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI())\n",
    "\n",
    "commands = [\"obsidian.search\", \"apple-notes.search\", \"notion.search\"]\n",
    "queries = [\n",
    "    [\n",
    "        \"Seems like the missing ingredient for the hamburger recipe was msg, let's add that in to our Beef Cheeseburger recipe note\",\n",
    "        [\"apple-notes.search\"],\n",
    "    ],\n",
    "    [\"What did I write about LSTMs previously?\", [\"obsidian.search\"]],\n",
    "    [\n",
    "        \"Can you note down that Jeanine is the new person in charge of the onboarding team in our team docs?\",\n",
    "        [\"notion.search\"],\n",
    "    ],\n",
    "]\n",
    "\n",
    "for query, expected_tool in queries:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can call tools to help you with your tasks. You have access to the following tools: \"\n",
    "                + str(commands),\n",
    "            }\n",
    "        ],\n",
    "        response_model=Literal[\n",
    "            \"obsidian.search\", \"apple-notes.search\", \"notion.search\"\n",
    "        ],\n",
    "    )\n",
    "    print(f\"{query} - Expected: {expected_tool} - Actual: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model struggles to call the correct tool for each query. Implicitly, it seems to call obsidian for all of the queries. This would be quite unacceptible for a personal assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about multi-step tasks? Let's imagine we have the following commands added to our existing commands\n",
    "\n",
    "- `gmail.send_email`\n",
    "- `gmail.search`\n",
    "- `hubspot.create_contact`\n",
    "- `hubspot.search`\n",
    "- `hubspot.update_contact`\n",
    "\n",
    "Let's see how our model performs with a few commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "Hey can you send an email to Sarah about the new project we've been approved for and cc our client on it? The POC \n",
       "is hubert from Nvidia - \n",
       "Expected: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'gmail.send_email'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hubspot.search_contact'</span><span style=\"font-weight: bold\">]</span>\n",
       "Actual: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'gmail.search_contact'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hubspot.search_contact'</span><span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "Hey can you send an email to Sarah about the new project we've been approved for and cc our client on it? The POC \n",
       "is hubert from Nvidia - \n",
       "Expected: \u001b[1m[\u001b[0m\u001b[32m'gmail.send_email'\u001b[0m, \u001b[32m'hubspot.search_contact'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Actual: \u001b[1m[\u001b[0m\u001b[32m'gmail.search_contact'\u001b[0m, \u001b[32m'hubspot.search_contact'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "Send Rupert the booking confirmation for our Shinjuku hotel booking. It's inside my personal email at \n",
       "josh@gmail.com - \n",
       "Expected: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'gmail.search_email'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gmail.search_contact'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gmail.send_email'</span><span style=\"font-weight: bold\">]</span>\n",
       "Actual: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'gmail.search'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gmail.search_contact'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hubspot.search_contact'</span><span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "Send Rupert the booking confirmation for our Shinjuku hotel booking. It's inside my personal email at \n",
       "josh@gmail.com - \n",
       "Expected: \u001b[1m[\u001b[0m\u001b[32m'gmail.search_email'\u001b[0m, \u001b[32m'gmail.search_contact'\u001b[0m, \u001b[32m'gmail.send_email'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Actual: \u001b[1m[\u001b[0m\u001b[32m'gmail.search'\u001b[0m, \u001b[32m'gmail.search_contact'\u001b[0m, \u001b[32m'hubspot.search_contact'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from typing import Literal\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI())\n",
    "\n",
    "commands = [\n",
    "    \"obsidian.search\",\n",
    "    \"apple-notes.search\",\n",
    "    \"notion.search\",\n",
    "    \"gmail.search_email\",\n",
    "    \"gmail.send_email\",\n",
    "    \"gmail.search_contact\",\n",
    "    \"gmail.search\",\n",
    "    \"hubspot.create_contact\",\n",
    "    \"hubspot.search_contact\",\n",
    "    \"hubspot.update_contact\",\n",
    "]\n",
    "queries = [\n",
    "    [\n",
    "        \"Hey can you send an email to Sarah about the new project we've been approved for and cc our client on it? The POC is hubert from Nvidia\",\n",
    "        [\"gmail.send_email\", \"hubspot.search_contact\"],\n",
    "    ],\n",
    "    [\n",
    "        \"Send Rupert the booking confirmation for our Shinjuku hotel booking. It's inside my personal email at josh@gmail.com\",\n",
    "        [\"gmail.search_email\", \"gmail.search_contact\", \"gmail.send_email\"],\n",
    "    ],\n",
    "]\n",
    "\n",
    "for query, expected_tool in queries:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can call tools to help you with your tasks. You have access to the following tools: \"\n",
    "                + str(commands),\n",
    "            }\n",
    "        ],\n",
    "        response_model=list[\n",
    "            Literal[\n",
    "                \"obsidian.search\",\n",
    "                \"apple-notes.search\",\n",
    "                \"notion.search\",\n",
    "                \"gmail.send_email\",\n",
    "                \"gmail.search_contact\",\n",
    "                \"gmail.search\",\n",
    "                \"hubspot.create_contact\",\n",
    "                \"hubspot.search_contact\",\n",
    "                \"hubspot.update_contact\",\n",
    "            ]\n",
    "        ],\n",
    "    )\n",
    "    print(f\"\\n\\n{query} - \" f\"\\nExpected: {expected_tool}\" f\"\\nActual: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is worse for the multi-step tasks. \n",
    "\n",
    "For the first and second example, we can see that it completely forgets to call the `gmail.send_email` task. It seems to default to search_contact for both gmail and hubspot by default instead of intuiting that hubspot should be called for professional contacts and gmail should be called for personal contacts.\n",
    "\n",
    "This is something that a few shot example could help with potentially or by users providing more context (either through a prompt or by updating the command/extension descriptions manually in their application).\n",
    "\n",
    "Now that we've identified some of these failure points, let's start generating our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Initial Queries\n",
    "\n",
    "Let's think about what we want to generate\n",
    "\n",
    "1. **Tool Calls** : Our queries should require 1-2 tools to be called\n",
    "2. **As user commands** : Most of these queries will be in the form of user queries (Eg. `send an email to Sarah about the Orion project and cc james`) that are more direct rather than conversational in nature (Eg. `Hey I hope you're doing well on your end. I was thinking that with the new updates to the orion project, we should probbaly cc sarah, what do you think?`)\n",
    "3. **Diverse** : We want to generate queries that span a diverse set of tone and lengths (Eg. we want queries that span from `send email sarah` to `hey can you send an email to Sarah, she's on my personal email`)\n",
    "\n",
    "Each test query will be a json object with the following fields\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"query\": str\n",
    "    \"labels\": list[str] # This is the `extension_name.command_name` of the tools that are called in the query - this helps us avoid issues where different extensions might have command names that are the same\n",
    "}\n",
    "```\n",
    "\n",
    "We'll write all of our queries to a `queries.jsonl` file and use that to store the queries we've generated. Since it's relatively simple to look at these queries in the default text editor, we'll just use that to eyeball and delete queries that don't make the cut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'command_name': 'searchNote',\n",
       " 'extension_name': 'obsidian',\n",
       " 'extension_description': \"I use obsidian to take down notes when I'm studying or taking online courses. I've been taking a variety of different courses on topics such as machine learning, marketing, copywriting etc. I'll use this specific extension when I want to search for notes on a specific topic or ask questions about a topic. Sometimes I might also want to create a quick dailyNote to log my progress for the day.\",\n",
       " 'command_description': 'Full-text search across all vault notes and their metadata'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load and parse the commands.yaml file\n",
    "with open(\"commands.yaml\", \"r\") as file:\n",
    "    commands_data = yaml.safe_load(file)\n",
    "\n",
    "# Extract extensions\n",
    "extensions = commands_data[\"extensions\"]\n",
    "commands = []\n",
    "\n",
    "for extension_name, extension_data in extensions.items():\n",
    "    for command in extension_data[\"commands\"]:\n",
    "        commands.append(\n",
    "            {\n",
    "                \"command_name\": command[\"name\"],\n",
    "                \"extension_name\": extension_name,\n",
    "                \"extension_description\": extension_data[\"description\"],\n",
    "                \"command_description\": command[\"description\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, field_validator, ValidationInfo\n",
    "from asyncio import Semaphore\n",
    "import random\n",
    "\n",
    "\n",
    "class SyntheticQuery(BaseModel):\n",
    "    chain_of_thought: str\n",
    "    query: str\n",
    "    commands: list[str]\n",
    "\n",
    "    @field_validator(\"commands\")\n",
    "    def validate_commands(cls, v: list[str], info: ValidationInfo):\n",
    "        context = info.context\n",
    "        commands = context[\"commands\"]\n",
    "        command_names = set(\n",
    "            [\n",
    "                f\"{command['extension_name']}.{command['command_name']}\"\n",
    "                for command in commands\n",
    "            ]\n",
    "        )\n",
    "        for command in v:\n",
    "            if command not in command_names:\n",
    "                raise ValueError(f\"Command {command} not found in commands\")\n",
    "\n",
    "        return v\n",
    "\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())\n",
    "\n",
    "\n",
    "async def generate_synthetic_query(\n",
    "    client: instructor.AsyncInstructor, commands: list[dict], sem: Semaphore\n",
    "):\n",
    "    tone = [\"natural\", \"curt and concise\", \"impatient\", \"slightly verbose\"]\n",
    "    async with sem:\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"\"\"\n",
    "                Generate a natural user message that would require using one or more of the following commands:\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                - {{ command['extension_name'] }}.{{ command['command_name'] }} : {{ command['command_description'] }}\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "\n",
    "                Requirements for the generated message:\n",
    "                - Do not explicitly mention any extension names or command names\n",
    "                - The message should clearly require using at least one of the commands' functionality\n",
    "                - Keep the message natural and conversational. It should be in the form of a message, remember that users are lazy and will type very short messages if possible.\n",
    "                - Focus on what the user is trying to achieve\n",
    "                - Have a tone of {{ tone }} with a length that's around {{ length }} words\n",
    "                - Make sure to have specific details in the query (Eg. the course, client name, project task achieved, specific feature being rolled out). These should be realistic (Eg. ACME Corp is a horrible name but Nike is a good one)\n",
    "                - The message can require multiple commands if it makes sense for the user's goal\n",
    "\n",
    "                <samples>\n",
    "                1. Can you help send an email to Sarah about the new project we've been approved for and cc our client on it? The POC is hubert from Nvidia\n",
    "                2. Create a new calendar event for the 18th of December at 10am\n",
    "                3. What's the temperature now in Taipei?\n",
    "                </samples>\n",
    "                \"\"\",\n",
    "                }\n",
    "            ],\n",
    "            context={\n",
    "                \"commands\": commands,\n",
    "                \"tone\": random.choice(tone),\n",
    "                \"length\": random.randint(5, 20),\n",
    "            },\n",
    "            response_model=SyntheticQuery,\n",
    "        )\n",
    "        return {\n",
    "            \"query\": resp.query,\n",
    "            \"labels\": resp.commands,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "import json\n",
    "\n",
    "sem = Semaphore(10)\n",
    "with open(\"queries.jsonl\", \"a+\") as f:\n",
    "    chosen_commands = random.sample(commands, random.randint(1, 5))\n",
    "    coros = [generate_synthetic_query(client, chosen_commands, sem) for _ in range(10)]\n",
    "    results = await asyncio.gather(*coros)\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate some initial queries and add them to a `queries.jsonl` file. In my case, this generated the following queries.\n",
    "\n",
    "```bash\n",
    "{\n",
    "    \"query\": \"Create a note for today's meeting summary with Intel. Seems like they're keen on expanding in Asia and getting more into AI\",\n",
    "    \"labels\": [\"notion.quickCapture\"]\n",
    "}\n",
    "{\n",
    "    \"query\": \"Can you compile all of the open PRs that have been tagged under the UI refactor project and add them to a new page in Notion?\",\n",
    "    \"labels\": [\n",
    "        \"jira.searchTicket\",\n",
    "        \"github.searchPullRequests\", \n",
    "        \"notion.createPage\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Now that we've generated these queries, let's use them to seed our prompt with some few shot examples by randomly sampling a few queries from the `queries.jsonl` file each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())\n",
    "\n",
    "\n",
    "async def generate_synthetic_query(\n",
    "    client: instructor.AsyncInstructor,\n",
    "    commands: list[dict],\n",
    "    queries: list[dict],\n",
    "    sem: Semaphore,\n",
    "):\n",
    "    tone = [\"natural\", \"curt and concise\", \"impatient\", \"slightly verbose\"]\n",
    "    async with sem:\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"\"\"\n",
    "                Generate a natural user message that would require using one or more of the following commands:\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                - {{ command['extension_name'] }}.{{ command['command_name'] }} : {{ command['command_description'] }}\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "\n",
    "                Requirements for the generated message:\n",
    "                - Do not explicitly mention any extension names or command names\n",
    "                - The message should clearly require using at least one of the commands' functionality\n",
    "                - Keep the message natural and conversational. It should be in the form of a message, remember that users are lazy and will type very short messages if possible.\n",
    "                - Focus on what the user is trying to achieve\n",
    "                - Have a tone of {{ tone }} with a length that's around {{ length }} words\n",
    "                - Make sure to have specific details in the query (Eg. the course, client name, project task achieved, specific feature being rolled out). These should be realistic (Eg. ACME Corp is a horrible name but Nike is a good one)\n",
    "                - The message can require multiple commands if it makes sense for the user's goal\n",
    "\n",
    "                <samples>\n",
    "                {% for query in queries %}\n",
    "                - {{ query['query'] }} : {{ query['labels'] }}\n",
    "                {% endfor %}\n",
    "                </samples>\n",
    "                \"\"\",\n",
    "                }\n",
    "            ],\n",
    "            context={\n",
    "                \"commands\": commands,\n",
    "                \"tone\": random.choice(tone),\n",
    "                \"length\": random.randint(5, 20),\n",
    "                \"queries\": queries,\n",
    "            },\n",
    "            response_model=SyntheticQuery,\n",
    "        )\n",
    "        return {\n",
    "            \"query\": resp.query,\n",
    "            \"labels\": resp.commands,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "sem = Semaphore(10)\n",
    "queries = [json.loads(line) for line in open(\"queries.jsonl\", \"r\")]\n",
    "\n",
    "with open(\"queries.jsonl\", \"a+\") as f:\n",
    "    coros = []\n",
    "\n",
    "    for _ in range(15):\n",
    "        chosen_commands = random.sample(commands, random.randint(1, 10))\n",
    "        chosen_queries = random.sample(queries, random.randint(1, 10))\n",
    "        coros.append(\n",
    "            generate_synthetic_query(client, chosen_commands, chosen_queries, sem)\n",
    "        )\n",
    "\n",
    "    results = await asyncio.gather(*coros)\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking Precision and Recall\n",
    "\n",
    "Now that we've generated our dataset, we can start benchmarking the precision and recall of our model. We'll start by loading in the queries that we've generated and then seeing what the precion and recall of our model is. We've provided a function to evaluate the precision and recall of our model in a `helper.py` file that we defined in the`1. Evaluate Tools.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33, 1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import calculate_precision, calculate_recall\n",
    "\n",
    "\n",
    "preds = [\"a\", \"b\", \"c\"]\n",
    "labels = [\"a\"]\n",
    "\n",
    "calculate_precision(preds, labels), calculate_recall(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that precision is 0.33 since only 1 item is relevant but 3 items were predicted. Recall is 1 since all of the relevant items ( in labels ) appeared in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def validate_queries(queries: list[dict],commands: list[dict]):\n",
    "    valid_commands = set([f\"{command['extension_name']}.{command['command_name']}\" for command in commands])\n",
    "    for query in queries:\n",
    "        for label in query[\"labels\"]:\n",
    "            if label not in valid_commands:\n",
    "                raise ValueError(f\"Command {label} not found in commands\")\n",
    "    return True\n",
    "\n",
    "\n",
    "queries = [json.loads(line) for line in open(\"queries.jsonl\", \"r\")]\n",
    "commands = read_and_flatten_commands(\"commands.yaml\")\n",
    "\n",
    "# Validate that all query labels are valid according to a given command.yaml file\n",
    "validate_queries(queries, commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, field_validator, ValidationInfo\n",
    "import instructor\n",
    "\n",
    "\n",
    "class Commands(BaseModel):\n",
    "    commands: list[str]\n",
    "\n",
    "    @field_validator(\"commands\")\n",
    "    def validate_commands(cls, v: list[str], info: ValidationInfo):\n",
    "        context = info.context\n",
    "        commands = context[\"commands\"]\n",
    "        command_names = set(\n",
    "            [\n",
    "                f\"{command['extension_name']}.{command['command_name']}\"\n",
    "                for command in commands\n",
    "            ]\n",
    "        )\n",
    "        for command in v:\n",
    "            if command not in command_names:\n",
    "                raise ValueError(f\"Command {command} not found in commands\")\n",
    "\n",
    "        return v\n",
    "\n",
    "\n",
    "async def generate_commands(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[dict]\n",
    "):\n",
    "    resp =  await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant that can call tools to help you with your tasks. Only use the following commands provided below.\n",
    "\n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                - {{ command['extension_name'] }}.{{ command['command_name'] }}\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-6-1734452916 is running at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1734452916\n",
      "function-calling (data): 44it [00:00, 268630.82it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56aae9a72b984b28917b91c71afb1e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "function-calling (tasks):   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-6-1734452916 compared to week-6-1734452839:\n",
      "70.43% (-15.55%) 'recall'    score\t(2 improvements, 9 regressions)\n",
      "67.80% (-13.64%) 'precision' score\t(1 improvements, 8 regressions)\n",
      "\n",
      "0.79s (+16.35%) 'duration'\t(12 improvements, 32 regressions)\n",
      "\n",
      "See results for week-6-1734452916 at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1734452916\n"
     ]
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "import openai\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    return [\n",
    "        Score(\n",
    "            name=\"precision\",\n",
    "            score=calculate_precision(kwargs[\"expected\"], output),\n",
    "        ),\n",
    "        Score(\n",
    "            name=\"recall\",\n",
    "            score=calculate_recall(kwargs[\"expected\"], output),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())   \n",
    "commands = read_and_flatten_commands(\"commands.yaml\")\n",
    "\n",
    "async def task(query: str, hooks):\n",
    "    return await generate_commands(query, client, commands)\n",
    "\n",
    "base_case = await Eval(\n",
    "    \"function-calling\",\n",
    "    data=lambda: [\n",
    "        {\n",
    "            \"input\": row[\"query\"],\n",
    "            \"expected\": row[\"labels\"],\n",
    "        }\n",
    "        for row in queries\n",
    "    ],\n",
    "    task=task,\n",
    "    max_concurrency=10,\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performance\n",
    "\n",
    "## Adding Detailed Descriptions\n",
    "\n",
    "One of the common failure points that we identified was that given a simple function name, our model would struggle to call the correct tool. Let's try to see if we can improve the performance of our model by adding more detailed descriptions to our commands.\n",
    "\n",
    "Luckily, we've already done so in the `commands.yaml` file. Let's see if this improves the performance of our model. Since all this requires is modifying the jinja templating in our original file, minimal changes are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-6-1734452930 is running at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1734452930\n",
      "function-calling (data): 44it [00:00, 123197.18it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7420a489928146a88d2f7b0af5a425d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "function-calling (tasks):   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-6-1734452930 compared to week-6-1734452916:\n",
      "75.36% (+04.93%) 'recall'    score\t(5 improvements, 3 regressions)\n",
      "72.34% (+04.55%) 'precision' score\t(5 improvements, 3 regressions)\n",
      "\n",
      "0.63s (-15.06%) 'duration'\t(34 improvements, 10 regressions)\n",
      "\n",
      "See results for week-6-1734452930 at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1734452930\n"
     ]
    }
   ],
   "source": [
    "async def generate_commands_with_descriptions(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[dict]\n",
    "):\n",
    "    resp =  await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant that can execute command(s) listed below to help answer a user query.\n",
    "\n",
    "                Only use the following commands provided below. A description of each command and its name is provided to help you understand what executing the command will do.\n",
    "                \n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                - Command Name : {{ command['extension_name'] }}.{{ command['command_name'] }}\n",
    "                  Description  : ({{ command['command_description'] }})\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())   \n",
    "commands = read_and_flatten_commands(\"commands.yaml\")\n",
    "\n",
    "async def task(query: str, hooks):\n",
    "    return await generate_commands_with_descriptions(query, client, commands)\n",
    "\n",
    "descriptions = await Eval(\n",
    "    \"function-calling\",\n",
    "    data=lambda: [\n",
    "        {\n",
    "            \"input\": row[\"query\"],\n",
    "            \"expected\": row[\"labels\"],\n",
    "        }\n",
    "        for row in queries\n",
    "    ],\n",
    "    task=task,\n",
    "    max_concurrency=10,\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyze the results of this evaluation to see if there are specific classes of tools that our model struggles with. By identifying these classes with low recall, we can add them as few shot examples to our prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool</th>\n",
       "      <th>Correct Identification</th>\n",
       "      <th>Total Targets</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>notion.quickCapture</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>slack.setPresence</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jira.searchIssue</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>notion.search</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>notion.createPage</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>github.searchPullRequests</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calendar.cancelEvent</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>youtube.searchChannel</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>calendar.addEvent</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>github.getNotifications</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Tool  Correct Identification  Total Targets  Recall\n",
       "14        notion.quickCapture                       0              1    0.00\n",
       "6           slack.setPresence                       0              1    0.00\n",
       "25           jira.searchIssue                       1              5    0.20\n",
       "10              notion.search                       1              5    0.20\n",
       "11          notion.createPage                       2              6    0.33\n",
       "20  github.searchPullRequests                       1              2    0.50\n",
       "3        calendar.cancelEvent                       2              3    0.67\n",
       "24      youtube.searchChannel                       2              3    0.67\n",
       "12          calendar.addEvent                       4              5    0.80\n",
       "26    github.getNotifications                       1              1    1.00"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = [\n",
    "    {\n",
    "        \"pred\": item.output,\n",
    "        \"expected\": item.expected,\n",
    "    }\n",
    "    for item\n",
    "    in descriptions.results\n",
    "]\n",
    "\n",
    "# Get all unique tools\n",
    "all_tools = set()\n",
    "for tools in results:\n",
    "    all_tools.update(tools[\"pred\"])\n",
    "    all_tools.update(tools[\"expected\"])\n",
    "\n",
    "# For each item, we'll count the number of tools that were predicted correctly and the total number of tools that were expected\n",
    "expected_occurences = {tool: 0 for tool in all_tools}\n",
    "occurences = {tool: 0 for tool in all_tools}\n",
    "\n",
    "for item in results:    \n",
    "    expected_tools = set(item[\"expected\"])\n",
    "    predicted_tools = set(item[\"pred\"])\n",
    "\n",
    "    for tool in expected_tools:\n",
    "        expected_occurences[tool] += 1\n",
    "    \n",
    "    for tool in predicted_tools:\n",
    "        occurences[tool] += 1\n",
    "\n",
    "\n",
    "# Calculate per-tool recall\n",
    "per_tool_recall = []\n",
    "for tool in all_tools:\n",
    "    if expected_occurences[tool] == 0:\n",
    "        continue\n",
    "    per_tool_recall.append({\n",
    "        'Tool': tool,\n",
    "        'Correct Identification': occurences[tool],\n",
    "        'Total Targets': expected_occurences[tool],\n",
    "        \"Recall\": occurences[tool]/ expected_occurences[tool]\n",
    "    })\n",
    "\n",
    "pd.DataFrame(per_tool_recall).round(2).sort_values(\"Recall\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some tools that have low recall and see if we can brainstorm certain trends causing their low recall. These are going to be\n",
    "\n",
    "1. `notion.quickCapture`\n",
    "2. `notion.search`\n",
    "4. `notion.createPage`\n",
    "5. `jira.searchIssue`\n",
    "\n",
    "Let's pull out these specific examples from our dataset, compare the predicted and expected tools and see if we can brainstorm certain trends causing their low recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Query: Create a note for today's meeting summary with Intel. Seems like they're keen on expanding in Asia and getting more into AI\n",
      "        Expected: ['notion.createPage']\n",
      "        Predicted: ['apple-notes.quickActions']\n",
      "        \n",
      "\n",
      "        Query: Hey, what did Jeff say previously in our meeting with Kafka?\n",
      "        Expected: ['notion.search']\n",
      "        Predicted: ['slack.searchMessages']\n",
      "        \n",
      "\n",
      "        Query: Check if there's a meeting with John Williams this week and find old notes on the Apple Workstation project.\n",
      "        Expected: ['calendar.searchCalendar', 'notion.search']\n",
      "        Predicted: ['calendar.searchCalendar', 'apple-notes.search']\n",
      "        \n",
      "\n",
      "        Query: Can you compile the issues that have been tagged under the UI refactor project and add them to a new page in Notion?\n",
      "        Expected: ['jira.searchIssue', 'notion.createPage']\n",
      "        Predicted: ['jira.searchProject']\n",
      "        \n",
      "\n",
      "        Query: Find a random interesting topic to explore today and create a Notion page for it.\n",
      "        Expected: ['wikipedia.random-page', 'notion.createPage']\n",
      "        Predicted: ['wikipedia.random-page']\n",
      "        \n",
      "\n",
      "        Query: What did we discuss last week in the meeting with Nike?\n",
      "        Expected: ['notion.search']\n",
      "        Predicted: ['calendar.searchCalendar']\n",
      "        \n",
      "\n",
      "        Query: Can you organize notes from today's meeting about Nike's shoe lineup launch?\n",
      "        Expected: ['notion.createPage']\n",
      "        Predicted: ['obsidian.dailyNote']\n",
      "        \n",
      "\n",
      "        Query: Any updates for the UI refactor while I was away on leave?\n",
      "        Expected: ['jira.searchIssue', 'github.searchPullRequests']\n",
      "        Predicted: ['github.searchIssues']\n",
      "        \n",
      "\n",
      "        Query: Can we list all pending issues for the search optimization task and add them to our progress-tracking page in Notion?\n",
      "        Expected: ['jira.searchIssue', 'notion.quickCapture']\n",
      "        Predicted: ['jira.searchIssue']\n",
      "        \n",
      "\n",
      "        Query: Urgent! Fetch past notes on the Nestle marketing launch.\n",
      "        Expected: ['notion.search']\n",
      "        Predicted: ['obsidian.searchNote', 'apple-notes.search', 'notion.search', 'github.searchIssues']\n",
      "        \n",
      "\n",
      "        Query: create a new feature branch for the UI refactor and link all the issues you've found about onboarding issues in the PR description\n",
      "        Expected: ['github.createBranch', 'jira.searchIssue']\n",
      "        Predicted: ['github.createBranch']\n",
      "        \n",
      "\n",
      "        Query: Find any open issues for the 'Login Feature' and discussions from 'WebApp Team'.\n",
      "        Expected: ['jira.searchIssue', 'github.searchDiscussions']\n",
      "        Predicted: ['github.searchIssues', 'github.searchDiscussions']\n",
      "        \n",
      "\n",
      "        Query: search for notes on our smartphone release campaign, find YouTube reviews, and schedule a meeting to discuss tomorrow afternoon.\n",
      "        Expected: ['notion.search', 'youtube.searchChannel', 'calendar.addEvent']\n",
      "        Predicted: ['obsidian.searchNote', 'youtube.searchVideos', 'calendar.addEvent']\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "problematic_classes = [\"notion.quickCapture\", \"notion.search\", 'notion.createPage', 'jira.searchIssue']\n",
    "\n",
    "for item in descriptions.results:\n",
    "    if any(class_name in item.expected for class_name in problematic_classes) and item.expected != item.output:\n",
    "        print(f\"\"\"\n",
    "        Query: {item.input}\n",
    "        Expected: {item.expected}\n",
    "        Predicted: {item.output}\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a few things here\n",
    "\n",
    "1. `searchJiraIssue` : The model rarely calls `jira.searchIssue`. And when it identifies that it needs issue information, it tends to call `github.searchIssue` instead. It also seems to be confused between `jira.searchIssue` and `jira.searchProject` in one instance.\n",
    "\n",
    "2. `notion.search` : We want our model to call `notion.search` when the user is refering to work meetings or documents. However, in the queries above, when it was prompted to search for meeting notes indirectly (Eg. What did we discuss in the meeting with Nike), it called `calendar.searchEvent` instead. Additionally, when it was prompted to search for `can you organize notes from today's meeting about Nike's shoe lineup launch?`, it called `obsidian instead. In one other instance, it called `apple-notes.search` instead.\n",
    "\n",
    "3. `notion.quickCapture` : We want our model to call `notion.quickCapture` when the user is creating a new note that contains a lot of information via a brain dump. However, in the queries above, when it was prompted to create a new note, it called `notion.createPage` instead. Therefore we'll need to add a few shot example to our prompt for `notion.quickCapture` to help the model understand the context of the user's request.\n",
    "\n",
    "Let's try targetting these few specific examples to improve the performance of our model in the few shot examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Few Shot Examples\n",
    "\n",
    "If we were to deploy this in production, we could also imagine that we'd want to add some few shot examples. We want to do so because it allows the model to be able to use those few shot examples to understand the context of the user's request.\n",
    "\n",
    "In a production application, we might obtain these examples by saving user queries and the tools they selected in the end in a local vector database. When the user makes a request, we'd then retrieve the most similar examples and include them in the prompt. \n",
    "\n",
    "One piece of low hanging fruit is providing context for which note taking app to choose - `obsidian`, `notion` or `apple-notes`. We'll add a few shot example to our prompt for each so our model can use this context to make a better decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-6-1734453148 is running at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1734453148\n",
      "function-calling (data): 44it [00:00, 153280.21it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4776da114bbf4c9dacc10e5eddbbe77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "function-calling (tasks):   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-6-1734453148 compared to week-6-1734453133:\n",
      "83.70% (-) 'recall'    score\t(0 improvements, 0 regressions)\n",
      "81.43% (-) 'precision' score\t(0 improvements, 0 regressions)\n",
      "\n",
      "0.76s (-02.20%) 'duration'\t(24 improvements, 20 regressions)\n",
      "\n",
      "See results for week-6-1734453148 at https://www.braintrust.dev/app/567/p/function-calling/experiments/week-6-1734453148\n"
     ]
    }
   ],
   "source": [
    "async def generate_commands_with_few_shots(\n",
    "    query: str, client: instructor.AsyncInstructor, commands: list[dict]\n",
    "):\n",
    "    resp =  await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                You are a helpful assistant that can execute command(s) listed below to help answer a user query.\n",
    "\n",
    "                Only use the following commands provided below. A description of each command and its name is provided to help you understand what executing the command will do.\n",
    "                \n",
    "                <commands>\n",
    "                {% for command in commands %}\n",
    "                - Command Name : {{ command['extension_name'] }}.{{ command['command_name'] }}\n",
    "                  Description  : ({{ command['command_description'] }})\n",
    "                {% endfor %}\n",
    "                </commands>\n",
    "\n",
    "                <examples>\n",
    "                User: grab all of  the issues that we haven't tackled for the new migration over to use Veact and send an slack message to chase the Gemini team to finish them up\n",
    "                Assistant: [jira.searchIssue, slack.sendMessage]\n",
    "\n",
    "                User: What were some of the updates to the open issue we've been tracking for the new migration over to use Veact?\n",
    "                Assistant: [jira.searchIssue]\n",
    "\n",
    "                User: Is there an open issue that's tracking the customer complaints that we've been recieving about the new refactors?\n",
    "                Assistant: [jira.searchIssue]\n",
    "\n",
    "                User: Can you grab the meeting notes previously from the meeting with Eva Air?\n",
    "                Assistant: [notion.search]\n",
    "\n",
    "                User: it seems like one of the big challenges that our client will face moving into the SEA market is that they need to heavily localise their brand and at the same time build a working relatonship with the local manufacturers/government officials. I'll need to spend some time next week to really sit down and think about this - we need to think about who to introduce to them, the markets to prioritize and the best way to get them to localise their brand. Let's make a new note for this moving forward.\n",
    "                Assistant: [notion.quickCapture]\n",
    "\n",
    "                User: Can you grab the intern onboarding documents from the last quarter?\n",
    "                Assistant: [notion.search]\n",
    "\n",
    "                User: Can you help me put together my shoppong list later for dinner? I need to buy 2 loaves of bread, some milk and some eggs.\n",
    "                Assistant: [apple-notes.quickActions]\n",
    "                </examples>\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        response_model=Commands,\n",
    "        context={\"commands\": commands},\n",
    "    )\n",
    "    return resp.commands\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())   \n",
    "commands = read_and_flatten_commands(\"commands.yaml\")\n",
    "\n",
    "async def task(query: str, hooks):\n",
    "    return await generate_commands_with_few_shots(query, client, commands)\n",
    "\n",
    "few_shots = await Eval(\n",
    "    \"function-calling\",\n",
    "    data=lambda: [\n",
    "        {\n",
    "            \"input\": row[\"query\"],\n",
    "            \"expected\": row[\"labels\"],\n",
    "        }\n",
    "        for row in queries\n",
    "    ],\n",
    "    task=task,\n",
    "    max_concurrency=10,\n",
    "    scores=[evaluate_braintrust],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Case</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Descriptions</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Few Shots</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Approach  recall  precision\n",
       "0     Base Case    0.70       0.68\n",
       "1  Descriptions    0.75       0.72\n",
       "2     Few Shots    0.84       0.81"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = [\n",
    "    [\"Base Case\" ,base_case],\n",
    "    [\"Descriptions\" ,descriptions],\n",
    "    [\"Few Shots\" ,few_shots]\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for label, item in results:\n",
    "    item_score = {\n",
    "        metric: item.summary.scores[metric].score  for metric in item.summary.scores\n",
    "    }\n",
    "    scores.append({\n",
    "        \"Approach\": label,\n",
    "        **item_score\n",
    "    })\n",
    "\n",
    "pd.DataFrame(scores).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "| Approach | Recall | Precision |\n",
    "| -------- | --------- | ------ |\n",
    "| Base Case | 0.70 | 0.68 |\n",
    "| Descriptions | 0.75 | 0.72 |\n",
    "| Few Shots | 0.84 | 0.81 |\n",
    "\n",
    "In this specific case, we found that adding descriptions and few shots to our prompt has improved the precision and recall of our model. This is because it increases the context of the user's request and gives the model more examples to learn from. \n",
    "\n",
    "However, let's take a step back and see what we had to do\n",
    "\n",
    "1. First we had to manually look through the dataset and identify specific tools that our model struggled with\n",
    "2. Then we had to manually write some few shot examples for each of these tools and the tools they were being confused with\n",
    "\n",
    "This is a difficult method to scale, especially as we increase the number of tools and commands that we have. \n",
    "\n",
    "Luckily, one potential method that we can use is to fetch relevant examples and tools from a vector database so we use the msot relevant few shot examples to the user's query. We'll explore this in the next notebook, where we'll generate more synthetic data and see how we can use this method to dynamically fetch relevant examples and tools to the user's query."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

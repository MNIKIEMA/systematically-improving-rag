{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 : Systematically Improving Your Rag Application\n",
    "\n",
    "## Why use LLM Generated Metadata\n",
    "\n",
    "LLM Generated Data can help us to add more structured fields to our data which allows us to perform more complex filtering before we do our retrieval.\n",
    "\n",
    "This means that we can potentially exclude irrelevant items by investing in query understanding and filtering by pre-processing our data.\n",
    "\n",
    "In this notebook, we'll be using the `ivanleomk/ecommerce-items` dataset that we generated in the previous notebook to add more structured fields to the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 418/418 [00:00<00:00, 18752.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ivanleomk/ecommerce-items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Teal Lace Top',\n",
       " 'category': 'Tops',\n",
       " 'subcategory': 'Blouses',\n",
       " 'brand': 'H&M',\n",
       " 'description': 'This elegant teal blouse features a delicate lace design on the upper portion, offering a chic and stylish look for work or special events. Perfect for pairing with high-waisted jeans for a sophisticated ensemble.',\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x1024>,\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll generate synthetic queries by mimicking a few different user intents\n",
    "\n",
    "- They want to find an item for a specific occasion\n",
    "- They're looking for an item to go with something else in their wardrobe\n",
    "- They want to find an item that's a fit for a specific style that they're exploring\n",
    "\n",
    "We'll also randomly add in some additional constraints to make these questions more interesting. These will be things like \"must be <color of item>\", \"must be <brand\">, \"made of <material>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "from asyncio import Semaphore, timeout\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "# Configure instructor with OpenAI client\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "class SyntheticQuery(BaseModel):\n",
    "    chain_of_thought: str\n",
    "    query: str\n",
    "\n",
    "\n",
    "# Example prompts for different intents\n",
    "INTENT_PROMPTS = {\n",
    "    \"occasion\": \"Generate a query from someone looking for clothing for a specific occasion like a wedding, party, job interview etc\",\n",
    "    \"outfit_matching\": \"Generate a query from someone trying to find an item that matches with something else in their wardrobe\",\n",
    "    \"style\": \"Generate a query from someone exploring a particular style or aesthetic like minimalist, streetwear, bohemian etc\",\n",
    "}\n",
    "\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))\n",
    "async def generate_synthetic_query(\n",
    "    intent_type: str, item: dict, sem: Semaphore\n",
    ") -> SyntheticQuery:\n",
    "    intent_prompt = INTENT_PROMPTS[intent_type]\n",
    "    image = item[\"image\"]\n",
    "    query_condition = [\n",
    "        \"the query must reference the item material \",\n",
    "        \"the query must reference the item brand indirectly\",\n",
    "        \"the query must reference the item color where possible ( or give a few options where the color is within)\",\n",
    "        \"the query must reference the item category/subcategory\",\n",
    "    ]\n",
    "\n",
    "    user_message_type = [\n",
    "        \"Short and concise (at most 1 sentence or 10 words)\",\n",
    "        \"longer and a bit more detailed (at most 2 sentences or 20 words)\",\n",
    "        \"short with some spelling mistakes (at most 1 sentence or 10 words)\",\n",
    "    ]\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".jpg\") as temp_file:\n",
    "        image.save(temp_file.name)\n",
    "\n",
    "        async with sem, timeout(30):\n",
    "            response = await client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_model=SyntheticQuery,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"\"\"Generate a hypothetical user query for this item that a user with {{ intent }} would ask which the following item is highly relevant for. Make sure that {{ query_condition }} and to reference specific attributes of the item where possible. The message should be {{ user_message_type }}.\n",
    "\n",
    "                        Here are examples of good queries:\n",
    "                        - 'I'm looking for a t-shirt that goes well with a striped green skirt I have. Ideally it'd be the same color if possible'\n",
    "                        - 'Need a cotton blouse in navy or dark blue to match my work pants'\n",
    "                        - 'Looking for a formal H&M blazer similar to their slim-fit black one but in grey'\"\"\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            \"\"\"\n",
    "                            Here is some information about the item\n",
    "\n",
    "                            Title: {{ item['title'] }}\n",
    "                            Description: {{ item['description'] }}\n",
    "                            Brand: {{ item['brand'] }}\n",
    "                            Category: {{ item['category'] }}\n",
    "                            Subcategory: {{ item['subcategory'] }}\n",
    "\n",
    "                            \n",
    "                            \"\"\",\n",
    "                            instructor.Image.from_path(temp_file.name),\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "                context={\n",
    "                    \"intent\": intent_prompt,\n",
    "                    \"item\": item,\n",
    "                    \"query_condition\": random.choice(query_condition),\n",
    "                    \"user_message_type\": random.choice(user_message_type),\n",
    "                },\n",
    "            )\n",
    "        return {\n",
    "            \"id\": item[\"id\"],\n",
    "            \"query\": response.query,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "intents = list(INTENT_PROMPTS.keys())\n",
    "sem = Semaphore(10)\n",
    "coros = [\n",
    "    generate_synthetic_query(random.choice(intents), item, sem)\n",
    "    for item in islice(ds[\"train\"], 30)\n",
    "]\n",
    "\n",
    "queries = await asyncio.gather(*coros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"queries_v2.jsonl\", \"w\") as f:\n",
    "    for query in queries:\n",
    "        f.write(json.dumps(query) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'query': 'Need teal lace top to wear for a wedding.'}\n",
      "{'id': 1, 'query': 'Looking for a cotton top to match black high-waisted jeans.'}\n",
      "{'id': 2, 'query': 'Need a vibrant green t-shirt for my casual jeans.'}\n",
      "{'id': 3, 'query': \"I'm searching for a blouse or top that complements a green and white striped pleated Zara skirt for a garden party.\"}\n",
      "{'id': 4, 'query': 'Looking for a trendy navy crop with bold sporty vibes?'}\n"
     ]
    }
   ],
   "source": [
    "for query in queries[:5]:\n",
    "    print(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our queries and see how well vector search performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-02T13:03:14Z WARN  lance::dataset] No existing dataset at /Users/ivanleo/Documents/coding/systematically-improving-rag/cohort_2/week5/lance/descriptions.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "db = lancedb.connect(\"./lance\")\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class Item(LanceModel):\n",
    "    id: int\n",
    "    text: str = func.SourceField()\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "\n",
    "\n",
    "if \"descriptions\" not in db.table_names():\n",
    "    table = db.create_table(\"descriptions\", schema=Item, mode=\"overwrite\")\n",
    "\n",
    "    items = [{\"id\": row[\"id\"], \"text\": row[\"description\"]} for row in ds[\"train\"]]\n",
    "\n",
    "    table.add(items)\n",
    "else:\n",
    "    table = db.open_table(\"descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733144834 is running at https://www.braintrust.dev/app/567/p/filters/experiments/week-5-1733144834\n",
      "filters (data): 30it [00:00, 42182.07it/s]\n",
      "filters (tasks): 100%|██████████| 30/30 [00:01<00:00, 22.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733144834 compared to main-1732799310:\n",
      "63.33% 'mrr@1'     score\n",
      "67.78% 'mrr@3'     score\n",
      "68.61% 'mrr@5'     score\n",
      "68.61% 'mrr@10'    score\n",
      "69.46% 'mrr@15'    score\n",
      "70.01% 'mrr@25'    score\n",
      "63.33% 'recall@1'  score\n",
      "73.33% 'recall@3'  score\n",
      "76.67% 'recall@5'  score\n",
      "76.67% 'recall@10' score\n",
      "86.67% 'recall@15' score\n",
      "96.67% 'recall@25' score\n",
      "\n",
      "0.84s duration\n",
      "\n",
      "See results for week-5-1733144834 at https://www.braintrust.dev/app/567/p/filters/experiments/week-5-1733144834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import get_metrics_at_k, task\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5, 10, 15, 25])\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=score_fn(output, kwargs[\"expected\"]),\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric, score_fn in metrics.items()\n",
    "    ]\n",
    "\n",
    "\n",
    "await Eval(\n",
    "    \"filters\",\n",
    "    data=lambda: [\n",
    "        {\n",
    "            \"input\": question[\"query\"],\n",
    "            \"expected\": [question[\"id\"]],\n",
    "        }\n",
    "        for question in queries\n",
    "    ],  # Replace with your eval dataset\n",
    "    task=lambda query: task(\n",
    "        user_query=query, table=table, reranker=None, max_k=25\n",
    "    ),  # Replace with your LLM call\n",
    "    scores=[evaluate_braintrust],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Teal Lace Top',\n",
       " 'category': 'Tops',\n",
       " 'subcategory': 'Blouses',\n",
       " 'brand': 'H&M',\n",
       " 'description': 'This elegant teal blouse features a delicate lace design on the upper portion, offering a chic and stylish look for work or special events. Perfect for pairing with high-waisted jeans for a sophisticated ensemble.',\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x1024>,\n",
       " 'id': 0,\n",
       " 'occasion': ['workwear', 'party'],\n",
       " 'style': ['elegant', 'contemporary'],\n",
       " 'material': ['cotton', 'synthetic']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Patch the OpenAI client with instructor\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "sem = Semaphore(10)\n",
    "\n",
    "\n",
    "# Define the metadata schema\n",
    "class ClothingMetadata(BaseModel):\n",
    "    occasion: list[Literal[\"casual\", \"smart-casual\", \"formal\", \"party\", \"workwear\"]]\n",
    "    style: list[\n",
    "        Literal[\n",
    "            \"bohemian\",\n",
    "            \"classic\",\n",
    "            \"contemporary\",\n",
    "            \"elegant\",\n",
    "            \"minimalist\",\n",
    "            \"preppy\",\n",
    "            \"romantic\",\n",
    "            \"streetwear\",\n",
    "            \"vintage\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    material: list[\n",
    "        Literal[\"cotton\", \"denim\", \"leather\", \"linen\", \"silk\", \"synthetic\", \"wool\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))\n",
    "async def extract_metadata(item: dict, sem: Semaphore) -> ClothingMetadata:\n",
    "    \"\"\"Extract metadata from clothing description and image using GPT-4V\"\"\"\n",
    "    async with sem, timeout(30):\n",
    "        # Create a temporary file to save the image\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=True) as temp_file:\n",
    "            # Save the PIL image to the temporary file\n",
    "            item[\"image\"].save(temp_file.name)\n",
    "            temp_file.flush()\n",
    "\n",
    "            metadata = await client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                response_model=ClothingMetadata,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            \"\"\"Analyze this clothing item and extract the following attributes:\n",
    "                                1. Occasions it's suitable for (casual, smart-casual, formal, party, workwear)\n",
    "                                2. Style categories (bohemian, classic, contemporary, elegant, minimalist, preppy, romantic, streetwear, vintage)\n",
    "                                3. Materials used (cotton, denim, leather, linen, silk, synthetic, wool)\n",
    "\n",
    "                                Here is some information about the item\n",
    "\n",
    "                                Title: {{ item['title'] }}\n",
    "                                Description: {{ item['description'] }}\n",
    "                                Brand: {{ item['brand'] }}\n",
    "                                Category: {{ item['category'] }}\n",
    "                                Subcategory: {{ item['subcategory'] }}\n",
    "                            \"\"\",\n",
    "                            instructor.Image.from_path(temp_file.name),\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "                context={\n",
    "                    \"item\": item,\n",
    "                },\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                **item,\n",
    "                **metadata.model_dump(),\n",
    "            }\n",
    "\n",
    "\n",
    "await extract_metadata(ds[\"train\"][0], sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 418/418 [02:28<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "coros = [extract_metadata(item, sem) for item in ds[\"train\"]]\n",
    "\n",
    "metadata = await asyncio.gather(*coros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "db = lancedb.connect(\"./lance\")\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "table_name = \"metadata\"\n",
    "\n",
    "\n",
    "class Item(LanceModel):\n",
    "    id: int\n",
    "    text: str = func.SourceField()\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "    occasions: str\n",
    "    style: str\n",
    "    material: str\n",
    "\n",
    "\n",
    "if table_name not in db.table_names():\n",
    "    table = db.create_table(table_name, schema=Item, mode=\"overwrite\")\n",
    "\n",
    "    # items = [{\"id\": row[\"id\"], \"text\": row[\"description\"]} for row in metadata]\n",
    "\n",
    "    # table.add(items)\n",
    "else:\n",
    "    table = db.open_table(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in metadata:\n",
    "    items.append(\n",
    "        {\n",
    "            \"id\": item[\"id\"],\n",
    "            \"text\": item[\"description\"],\n",
    "            \"occasions\": \", \".join(item[\"occasion\"]),\n",
    "            \"style\": \", \".join(item[\"style\"]),\n",
    "            \"material\": \", \".join(item[\"material\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "table.add(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'query': 'Need teal lace top to wear for a wedding.'},\n",
       " {'id': 1,\n",
       "  'query': 'Looking for a cotton top to match black high-waisted jeans.'},\n",
       " {'id': 2, 'query': 'Need a vibrant green t-shirt for my casual jeans.'},\n",
       " {'id': 3,\n",
       "  'query': \"I'm searching for a blouse or top that complements a green and white striped pleated Zara skirt for a garden party.\"},\n",
       " {'id': 4, 'query': 'Looking for a trendy navy crop with bold sporty vibes?'},\n",
       " {'id': 5, 'query': 'Streetwear style jeans with distressed finish pls?'},\n",
       " {'id': 6,\n",
       "  'query': 'Need a plaid crop top with thin straps for a summer party.'},\n",
       " {'id': 7,\n",
       "  'query': 'Looking for Zara plaid shorts with a tie waist for a picnic.'},\n",
       " {'id': 8,\n",
       "  'query': 'Looking for a neon yellow graphic T-shirt for streetwear vibe.'},\n",
       " {'id': 9, 'query': 'Looking for a cotton top to match classic denim jeans.'},\n",
       " {'id': 10,\n",
       "  'query': \"I'm attending a garden party and need a sleeveless shirt with eyelet detailing and beautiful gold accents. Would this Zara piece be suitable?\"},\n",
       " {'id': 11, 'query': 'Need olive jeans for casual party, are these cotton?'},\n",
       " {'id': 12,\n",
       "  'query': 'Seeking a casual jacket to match a grey graphic t-shirt.'},\n",
       " {'id': 13,\n",
       "  'query': 'Looking for a casual top to pair with my timeless blue denim bottoms that have a classic wash.'},\n",
       " {'id': 14, 'query': 'Looking for a floral Zara blouse with 3/4 sleeves.'},\n",
       " {'id': 15,\n",
       "  'query': 'Looking for a minimalist denim skirt with functional pockets?'},\n",
       " {'id': 16,\n",
       "  'query': 'Looking for a black cotton t-shirt to match my grey jeans.'},\n",
       " {'id': 17,\n",
       "  'query': 'Looking for a simple black top to pair with my classic washed, high-rise straight fit jeans for a casual look.'},\n",
       " {'id': 18,\n",
       "  'query': 'Looking for a formal lace blouse with elegant floral design.'},\n",
       " {'id': 19,\n",
       "  'query': 'Looking for a black leather belt to match my sleek buckle shoes.'},\n",
       " {'id': 20,\n",
       "  'query': \"I'm looking for tailored faux leather pants to complete my modern chic outfit. Do these Zara ones have that sophisticated vibe?\"},\n",
       " {'id': 21, 'query': 'Looking for comfy shorts that match a white tee I own.'},\n",
       " {'id': 22, 'query': 'Need elegant black trousers for relaxed office wear.'},\n",
       " {'id': 23, 'query': 'Need a white V-neck blouse for a casual job interview.'},\n",
       " {'id': 24,\n",
       "  'query': \"I'm looking for a versatile white V-neck top to pair with my black high-waisted Zara trousers for both casual and formal occasions.\"},\n",
       " {'id': 25,\n",
       "  'query': 'Searching for a soft printed high-neck blouse that pairs beautifully with my black pencil skirt for work events.'},\n",
       " {'id': 26,\n",
       "  'query': 'Looking for white slim-fit trousers for a minimalist chic look.'},\n",
       " {'id': 27,\n",
       "  'query': 'Seeking a chic blouse to complement Ann Taylor gold earrings.'},\n",
       " {'id': 28,\n",
       "  'query': 'Looking for a chic high neck lace bodysuit to pair with a pencil skirt for a sophisticated look.'},\n",
       " {'id': 29,\n",
       "  'query': 'Looking for a chic Guess blouse to complement my high-waisted pencil skirt with a belt detail for formal occasions.'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries = [json.loads(item) for item in open(\"queries.jsonl\").readlines()]\n",
    "queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(tags=['a', 'b', 'c'], categories=['foo', 'bar'], labels=['1', '2', '3'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from pydantic import BaseModel, PlainValidator\n",
    "\n",
    "def split_csv(v: str) -> list[str]:\n",
    "    return [x.strip() for x in v.split(',')] if isinstance(v, str) else v\n",
    "\n",
    "CsvList = Annotated[list[str], PlainValidator(split_csv)]\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    tags: CsvList\n",
    "    categories: CsvList  # Reuse the annotation\n",
    "    labels: CsvList      # Can use it multiple times\n",
    "\n",
    "model = MyModel(\n",
    "    tags=\"a,b,c\",\n",
    "    categories=\"foo,bar\",\n",
    "    labels=\"1,2,3\"\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from openai import AsyncOpenAI\n",
    "import instructor\n",
    "from asyncio import Semaphore, timeout\n",
    "from pydantic import BaseModel\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "# Define the metadata schema\n",
    "class MetadataFilters(BaseModel):\n",
    "    occasion: list[Literal[\"casual\", \"smart-casual\", \"formal\", \"party\", \"workwear\"]]\n",
    "    style: list[\n",
    "        Literal[\n",
    "            \"bohemian\",\n",
    "            \"classic\",\n",
    "            \"contemporary\",\n",
    "            \"elegant\",\n",
    "            \"minimalist\",\n",
    "            \"preppy\",\n",
    "            \"romantic\",\n",
    "            \"streetwear\",\n",
    "            \"vintage\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    material: list[\n",
    "        Literal[\"cotton\", \"denim\", \"leather\", \"linen\", \"silk\", \"synthetic\", \"wool\"]\n",
    "    ]\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))\n",
    "async def extract_metadata(id: int, query: str, sem: Semaphore) -> dict:\n",
    "    async with sem, timeout(30):\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=MetadataFilters,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You're an expert query understanding AI, extract out any relevant filters from the query. It's ok to return an empty list for that specific filter if it's not required/relevant to the query. Look closely at mentions of desired materials, styles and occasions of what the user is looking for\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"id\": id,\n",
    "        \"query\": query,\n",
    "        **resp.model_dump()\n",
    "    }\n",
    "\n",
    "sem = Semaphore(10)\n",
    "coros = [extract_metadata(query[\"id\"], query[\"query\"], sem) for query in queries]\n",
    "metadata = await asyncio.gather(*coros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'query': 'Need teal lace top to wear for a wedding.',\n",
       " 'occasion': ['formal'],\n",
       " 'style': [],\n",
       " 'material': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableItem(BaseModel):\n",
    "    id: int\n",
    "    text:str\n",
    "    occasions: CsvList\n",
    "    style: CsvList\n",
    "    material: CsvList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(item_values:list[str], filter_values:list[str]):\n",
    "    for filter_value in filter_values:\n",
    "        if filter_value in item_values:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def search_with_filter(query_with_filter:dict,table,max_k):\n",
    "    query = query_with_filter[\"query\"]\n",
    "    \n",
    "    items = [TableItem(**item) for item in table.search(query).limit(max_k).to_list()]\n",
    "\n",
    "\n",
    "    if query_with_filter['occasion']:\n",
    "        items = [item for item in items if apply_filter(item.occasions, query_with_filter['occasion'])]\n",
    "\n",
    "    if query_with_filter['style']:\n",
    "        items = [item for item in items if apply_filter(item.style, query_with_filter['style'])]\n",
    "\n",
    "    if query_with_filter['material']:\n",
    "        items = [item for item in items if apply_filter(item.material, query_with_filter['material'])]\n",
    "\n",
    "    return [item.id for item in items]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment week-5-1733149659 is running at https://www.braintrust.dev/app/567/p/filters/experiments/week-5-1733149659\n",
      "filters (data): 30it [00:00, 121927.44it/s]\n",
      "filters (tasks): 100%|██████████| 30/30 [00:01<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "week-5-1733149659 compared to main-1732799310:\n",
      "50.00% 'mrr@1'     score\n",
      "53.33% 'mrr@3'     score\n",
      "53.33% 'mrr@5'     score\n",
      "53.33% 'mrr@10'    score\n",
      "54.18% 'mrr@15'    score\n",
      "54.56% 'mrr@25'    score\n",
      "50.00% 'recall@1'  score\n",
      "56.67% 'recall@3'  score\n",
      "56.67% 'recall@5'  score\n",
      "56.67% 'recall@10' score\n",
      "66.67% 'recall@15' score\n",
      "73.33% 'recall@25' score\n",
      "\n",
      "1.19s duration\n",
      "\n",
      "See results for week-5-1733149659 at https://www.braintrust.dev/app/567/p/filters/experiments/week-5-1733149659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvalResultWithSummary(summary=\"...\", results=[...])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braintrust import Eval, Score\n",
    "from helpers import get_metrics_at_k, task\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5, 10, 15, 25])\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=score_fn(output, kwargs[\"expected\"]),\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric, score_fn in metrics.items()\n",
    "    ]\n",
    "\n",
    "\n",
    "await Eval(\n",
    "    \"filters\",\n",
    "    data=lambda: [\n",
    "        {\n",
    "            \"input\": question,\n",
    "            \"expected\": [question[\"id\"]],\n",
    "        }\n",
    "        for question in metadata\n",
    "    ],  # Replace with your eval dataset\n",
    "    task=lambda query: search_with_filter(\n",
    "        query, table=table,max_k=200\n",
    "    ),  # Replace with your LLM call\n",
    "    scores=[evaluate_braintrust],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

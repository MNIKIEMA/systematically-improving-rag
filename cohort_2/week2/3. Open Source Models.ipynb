{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematically Improving RAG\n",
    "\n",
    "Depending on your use-case, you might want to use an open source model instead of a proprietary one like Cohere. In this notebook, we'll look at how to use an open source model from hugging face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a similar setup as the previous notebook, creating a train-test-split and the fine-tuning the model on the training data.\n",
    "\n",
    "Let's first see how we can use the same metrics to evaluate the model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resolve the warning from huggingface/tokenizers about parallelism:\n",
    "# 1. Avoid using `tokenizers` before the fork if possible.\n",
    "# 2. Explicitly set the environment variable TOKENIZERS_PARALLELISM to either 'true' or 'false'.\n",
    "import os\n",
    "\n",
    "# Set the environment variable to disable parallelism warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "BASE_MODEL_NAME = \"BAAI/bge-base-en\"\n",
    "FINETUNED_MODEL_NAME = \"ivanleomk/finetuned-bge-base-en\"\n",
    "\n",
    "MODEL_OUTPUT_DIR = \"./models/bge-base-en\"\n",
    "WANDB_RUN_NAME = \"bge-base-en\"\n",
    "CATEGORIES_PATH = \"data/categories.json\"\n",
    "TRAIN_EVALUATOR_NAME = \"bge-base-en-train\"\n",
    "EVAL_EVALUATOR_NAME = \"bge-base-en-eval\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braintrust import init_dataset\n",
    "import json\n",
    "\n",
    "categories = json.load(open(CATEGORIES_PATH))\n",
    "dataset = init_dataset(project=\"fine-tuning\", name=\"Synthetic Transactions\")\n",
    "\n",
    "\n",
    "def get_dataset_split(split: str, dataset):\n",
    "    return [\n",
    "        {\n",
    "            \"input\": transaction[\"input\"],\n",
    "            \"expected\": transaction[\"expected\"],\n",
    "        }\n",
    "        for transaction in dataset\n",
    "        if transaction[\"metadata\"][\"split\"] == split\n",
    "    ]\n",
    "\n",
    "\n",
    "train_data = get_dataset_split(\"train\", dataset)\n",
    "eval_data = get_dataset_split(\"eval\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning\n",
    "\n",
    "We can fine-tune the model using the same approach as before. In this specific case, we'll define a train-test-split and fine-tune the model on the training data.\n",
    "\n",
    "- Train : Our model is trained on this data\n",
    "- Test :  We use this data to see how the model performs during each epoch\n",
    "- Eval : This is held out and only used at the end to see the model's performance.\n",
    "\n",
    "\n",
    "We'll do so with Sentence Transformers because it provides a large amount of loss functions to choose from out of the box and is compatible with Hugging Face, making it easy to upload and save the fine-tuned models when we're done.\n",
    "\n",
    "We'll be using the Batch Semi Hard Triplet Loss in this case. It helps with our model learning a decision boundary between the positive and negative examples.\n",
    "\n",
    "To do so, we'll need to create two formats of our dataset\n",
    "\n",
    "1. A Triplet Dataset - This is used by the evaluator to see the performance of the model;\n",
    "2. A transaction to label dataset - this is used to train the model so that it groups similar transactions together in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = get_dataset_split(\"train\", dataset)\n",
    "eval_data = get_dataset_split(\"eval\", dataset)\n",
    "\n",
    "test_data = train_data[: int(len(train_data) * TEST_SIZE)]\n",
    "train_data = train_data[int(len(train_data) * TEST_SIZE) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def create_labels(data):\n",
    "    label_to_example = defaultdict(list)\n",
    "\n",
    "    for item in data:\n",
    "        label_to_example[item[\"expected\"][0]].append(item)\n",
    "\n",
    "    return {label: idx for idx, label in enumerate(label_to_example.keys())}\n",
    "\n",
    "\n",
    "def create_sentence_to_label_dataset(data, label_to_idx):\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"sentence\": [item[\"input\"] for item in data],\n",
    "            \"label\": [label_to_idx[item[\"expected\"][0]] for item in data],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def create_triplet_dataset(data):\n",
    "    label_to_example = defaultdict(list)\n",
    "\n",
    "    for item in data:\n",
    "        label_to_example[item[\"expected\"][0]].append(item)\n",
    "\n",
    "    labels = set(label_to_example.keys())\n",
    "\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    for item in data:\n",
    "        label = item[\"expected\"][0]\n",
    "        anchor = item\n",
    "        positive = label\n",
    "        negative = random.choice([item for item in labels if item != label])\n",
    "        anchors.append(anchor)\n",
    "        positives.append(positive)\n",
    "        negatives.append(negative)\n",
    "\n",
    "    return {\"anchor\": anchors, \"positive\": positives, \"negative\": negatives}\n",
    "\n",
    "\n",
    "labels_to_idx = create_labels(train_data)\n",
    "\n",
    "train_triplets = create_triplet_dataset(train_data)\n",
    "test_triplets = create_triplet_dataset(test_data)\n",
    "eval_triplets = create_triplet_dataset(eval_data)\n",
    "\n",
    "sentence_to_label_train_dataset = create_sentence_to_label_dataset(\n",
    "    train_data, labels_to_idx\n",
    ")\n",
    "sentence_to_label_test_dataset = create_sentence_to_label_dataset(\n",
    "    test_data, labels_to_idx\n",
    ")\n",
    "sentence_to_label_eval_dataset = create_sentence_to_label_dataset(\n",
    "    eval_data, labels_to_idx\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bge-base-en-train_cosine_accuracy': 0.8461538461538461,\n",
       " 'bge-base-en-train_dot_accuracy': 0.15384615384615385,\n",
       " 'bge-base-en-train_manhattan_accuracy': 0.8557692307692307,\n",
       " 'bge-base-en-train_euclidean_accuracy': 0.8461538461538461,\n",
       " 'bge-base-en-train_max_accuracy': 0.8557692307692307}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import BatchSemiHardTripletLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "model = SentenceTransformer(BASE_MODEL_NAME)\n",
    "loss = BatchSemiHardTripletLoss(model)\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=MODEL_OUTPUT_DIR,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=WANDB_RUN_NAME,  # Will be used in W&B if `wandb` is installed\n",
    ")\n",
    "\n",
    "train_evaluator = TripletEvaluator(\n",
    "    anchors=train_triplets[\"anchor\"],\n",
    "    positives=train_triplets[\"positive\"],\n",
    "    negatives=train_triplets[\"negative\"],\n",
    "    name=TRAIN_EVALUATOR_NAME,\n",
    ")\n",
    "\n",
    "train_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7298c6753eb946fead20c28258f6a424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=65, training_loss=4.900086388221154, metrics={'train_runtime': 5.0757, 'train_samples_per_second': 204.897, 'train_steps_per_second': 12.806, 'total_flos': 0.0, 'train_loss': 4.900086388221154, 'epoch': 5.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=sentence_to_label_train_dataset,\n",
    "    eval_dataset=sentence_to_label_test_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=train_evaluator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bge-base-en-eval_cosine_accuracy': 0.9545454545454546,\n",
       " 'bge-base-en-eval_dot_accuracy': 0.045454545454545456,\n",
       " 'bge-base-en-eval_manhattan_accuracy': 0.9545454545454546,\n",
       " 'bge-base-en-eval_euclidean_accuracy': 0.9545454545454546,\n",
       " 'bge-base-en-eval_max_accuracy': 0.9545454545454546}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=eval_triplets[\"anchor\"],\n",
    "    positives=eval_triplets[\"positive\"],\n",
    "    negatives=eval_triplets[\"negative\"],\n",
    "    name=EVAL_EVALUATOR_NAME,\n",
    ")\n",
    "test_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/ivanleomk/finetuned-bge-base-en/commit/c3c83d0594e980f60275019f1cb16fba8738d27d'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(f\"models/finetuned-{BASE_MODEL_NAME}\")\n",
    "model.push_to_hub(FINETUNED_MODEL_NAME, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "def create_lancedb_table(model_name: str, categories: list[str]):\n",
    "    model = get_registry().get(\"huggingface\").create(name=model_name)\n",
    "\n",
    "\n",
    "    class Category(LanceModel):\n",
    "        text: str = model.SourceField()\n",
    "        embedding: Vector(model.ndims()) = model.VectorField()\n",
    "\n",
    "\n",
    "    db = lancedb.connect(\"./lancedb\")\n",
    "    table = db.create_table(\n",
    "        f\"categories-{model_name.replace('/', '-')}\", schema=Category, mode=\"overwrite\"\n",
    "    )\n",
    "\n",
    "    table.add(\n",
    "        [\n",
    "            {\n",
    "                \"text\": category[\"category\"],\n",
    "            }\n",
    "            for category in categories\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment synthetic-transactions-train-categories-BAAI-bge-base-en is running at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-BAAI-bge-base-en\n",
      "fine-tuning [experiment_name=synthetic-transactions-train-categories-BAAI-bge-base-en] (data): 66it [00:00, 182240.99it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6888d5801a24273a85c2201101e1ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fine-tuning [experiment_name=synthetic-transactions-train-categories-BAAI-bge-base-en] (tasks):   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en is running at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "synthetic-transactions-train-categories-BAAI-bge-base-en compared to synthetic-transactions-train-bdf7ddaa:\n",
      "36.36% (-19.70%) 'mrr@1'    score\t(6 improvements, 19 regressions)\n",
      "48.99% (-20.45%) 'mrr@3'    score\t(8 improvements, 29 regressions)\n",
      "51.41% (-19.17%) 'mrr@5'    score\t(8 improvements, 32 regressions)\n",
      "36.36% (-19.70%) 'recall@1' score\t(6 improvements, 19 regressions)\n",
      "68.18% (-18.18%) 'recall@3' score\t(0 improvements, 12 regressions)\n",
      "78.79% (-12.12%) 'recall@5' score\t(0 improvements, 8 regressions)\n",
      "\n",
      "5.77s (-89.66%) 'duration'\t(18 improvements, 48 regressions)\n",
      "\n",
      "See results for synthetic-transactions-train-categories-BAAI-bge-base-en at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-BAAI-bge-base-en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fine-tuning [experiment_name=synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en] (data): 66it [00:00, 88413.95it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c577fc69734357977d019830a1e808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fine-tuning [experiment_name=synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en] (tasks):…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en compared to synthetic-transactions-train-categories-BAAI-bge-base-en:\n",
      "56.06% (+19.70%) 'mrr@1'    score\t(19 improvements, 6 regressions)\n",
      "69.44% (+20.45%) 'mrr@3'    score\t(29 improvements, 8 regressions)\n",
      "70.58% (+19.17%) 'mrr@5'    score\t(32 improvements, 8 regressions)\n",
      "56.06% (+19.70%) 'recall@1' score\t(19 improvements, 6 regressions)\n",
      "86.36% (+18.18%) 'recall@3' score\t(12 improvements, 0 regressions)\n",
      "90.91% (+12.12%) 'recall@5' score\t(8 improvements, 0 regressions)\n",
      "\n",
      "5.58s (-18.99%) 'duration'\t(56 improvements, 10 regressions)\n",
      "\n",
      "See results for synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en\n"
     ]
    }
   ],
   "source": [
    "from indomee import calculate_metrics_at_k\n",
    "from braintrust import Score, Eval\n",
    "\n",
    "categories = json.load(open(CATEGORIES_PATH))\n",
    "base_table = create_lancedb_table(BASE_MODEL_NAME, categories)\n",
    "finetuned_table = create_lancedb_table(FINETUNED_MODEL_NAME, categories)\n",
    "\n",
    "db = lancedb.connect(\"/root/lancedb\")\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = calculate_metrics_at_k(\n",
    "        metrics=[\"mrr\", \"recall\"], k=[1, 3, 5], preds=output, labels=kwargs[\"expected\"]\n",
    "    )\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=metrics[metric],\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric in metrics\n",
    "    ]\n",
    "\n",
    "\n",
    "def task(user_query, table_to_query):\n",
    "    return [\n",
    "        item[\"text\"]\n",
    "        for item in table_to_query.search(user_query, query_type=\"vector\")\n",
    "        .limit(25)\n",
    "        .to_list()\n",
    "    ]\n",
    "\n",
    "for query_table in [base_table, finetuned_table]:\n",
    "    await Eval(\n",
    "        \"fine-tuning\",\n",
    "        experiment_name=f\"synthetic-transactions-train-{query_table.name}\",\n",
    "        data=lambda: eval_data,\n",
    "        task=lambda query: task(query, query_table),\n",
    "        scores=[evaluate_braintrust],\n",
    "        metadata={\"model\": query_table.name},\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
